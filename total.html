

 



<p>
A Brief Introduction to PBS
label:pbs
PBS or it Portable Batch System is queuing software that controls the flow
of jobs on distributed systems.  PBS has the capability to have different queues
with different priorities.  One of the complications of running a parallel 
machine is that not all jobs require all of the resources.  This means that
system resources would be idle if the system could only run one job at a time.
On the other hand, if there were no job control none of the jobs would run 
efficiently.  PBS is flexible enough to handle many different configurations.
This  of the class is intended to give you an introduction to the basic
functions of PBS as we use them on our clusters. We will introduce the
several of the commands in the exercises at the end of this .
<br>Queues, qsub, and the submit scripts
Queues are at the heart of PBS.  There are several types and a long list of
possible settings for each type.  This can be used to sort jobs by various 
resources, and assign them different priorities.  On our cluster we run with 
only one queue called router. 
<p>
Jobs are submitted to the queuing system using the command it qsub. In an 
environment that has need of greater complexity, the command can be use to
control which queue a job enters, when the job is run, and controlling various
other aspects of a job.  
<p>
While much of the job control can be accomplished using qsub command line 
parameters, a preferable method is to use submission scripts.  These scripts
can set the environment and PBS variables to control the run. This is a 
preferable method since it is much simpler to rerun a job with small changes.
<p>
Below is a sample script to run the HelloWorld program on 4 nodes.

#!/bin/sh
#PBS -l nodes=4
mpirun -np 4 -machinefile $PBS_NODEFILE HelloWorld

If these lines were in a file called hello.pbs, then the program HelloWorld
could be submitted to the cluster with the command "qsub hello.pbs".
Although this is a simple file, there are a few points of interest.  The line
"#PBS -l nodes =4" is a PBS directive line.  Any line that starts with #PBS
is interpreted as a directive.  In this case it is telling PBS that it 
needs 4 nodes to execute the program.  Notice that this number matches the
parameter -np in the mpirun line.  The number allocated by PBS must be greater
than or equal to the number requested by the mpirun command.  In the
mpirun line we have a PBS environment variable.  Although this is a shell
script PBS makes certain changes to the environment.  In this case, the list of 
nodes that PBS is making available is stored in the $PBS_NODEFILE variable
and passed to mpirun. 
<p>
If the above program were submitted with the qsub program above we would see
the following sequence of events.

&gt;qsub hello.pbs
&gt;100.mimir

This would be telling you that your job was assigned the number 100. When
the job was finished you would have two new files in this directory with
the names "hello.pbs.e100" and "hello.pbs.o100". The .e file contains the
output from standard error, and any errors that PBS encounters.  The .o file
contains the output from the submit script and the program.
<p>
The list below show some of the common modifications to the submit script
that you might want to use.
<p>
begindescription
<br>[#PBS -joe] Combine the error and output files.
<br>[#PBS -N ] Set the name of the job. This affects the name of the output
files.
<br>[#PBS -l] Sets the resource lists for the jobs -l can be followed by
a resource list which often includes the following <br>s.
   begin<br>ize
	  <br> nodes - Specifies which may be followed by a formatted string specifying which nodes to use.
	  <br> ncpus - Sets how many cpus are needed. This is more important with
SMP nodes, or in a pure SMP environment.
	  <br> walltime - Sets an upper limit on the length of the job.
	  <br> cputime - Sets an upper limit on the cpu time used for the job.
   end<br>ize
<br> [cd] Change the directory.
enddescription
<p>
There are many other options available and the complete Users Guide is available
on line from ftp.acomp.usf.edu.
<br>Exercises
<br>
<br> Create a submission script to run the diffusion program from the last 
  on eight nodes and submit it by logging on to mimir and using qsub.
<br> While everyone is running their programs on mimir, log onto mimir and
investigate the commands qstat, pbs_stats, xpbsmon and xpbs. You may have to
rerun jobs if they all finish too fast.

<p>
Further Reading
label:addmat 
begin<br>ize
<br> Books
begin<br>ize
   <br> it MPI-The Complete Reference by Snir,Otto,Huss-Lederman,Walker,andDongarra
   <br> it Parallel Programming with MPI by Peter S. Pacheco
end<br>ize
<br> On-line Tutorials
   begin<br>ize
   <br> OSC - http://oscinfo.osc.edu/training (requires free registration)
   <br> USF - http://rocs.acomp.usf.edu/tut/mpi.php
   end<br>ize
end<br>ize
<p>


 
<p>Introduction to MPI Programming in Fortran
<p>
it MPI or it Message Passing Interface indexMPI is not a
programming language.  It is a standard for implementing message
passing parallel programming. It is in most implementations a
library of functions or subprograms that can be called from other
languages, most often C or Fortran. MPI grew out from the
frustrations of programmers and researchers whose parallel code
was not portable due to proprietary programming interfaces. It was
developed by a forum with members from academia, government, and
industry.  MPI allows development of portable and efficient
parallel code. These libraries make many of the lower level
intricacies of parallel programming transparent to the programmer.
<p>
MPI is a form of message passing parallel programming, which is a
very popular parallel programming model. In this paradigm, the
processes run independently, and use communications for
synchronizing their efforts. For those of you with an interest in
the theory behind parallel programming, MPI is a form of SIMD or
SPMD parallel architecture.  This means that all of the processors
run the same program, but on different data.  Unlike a pure SIMD
architecture MPI does not force the program to run exactly the
same on all processors, but allows for differential execution.
<p>
These notes are not intended to be an in depth
exposition of even the introductory topics that are covered.
Rather they are intended to lead you through the examples which
should give you adequate exposure to begin using MPI. For more in
depth materials please see  ref:addmat which
lists additional pedagogical materials.
<p>
There are several commercial and free versions of these libraries.
The two most popular non-commercial implementations are it
LAM-MPI and it MPICH.  We will be using MPICH for this class.
<p>
 A first program
label:afp We will start with the traditional "Hello
World" program.  This will allow us to take a detailed look at the
minimal code necessary to run an MPI program. The code for this
and the other examples in this <p> are included in the bccode
directory on the lab machines.

    PROGRAM HELLOWORLD

    INCLUDE 'mpif.h'

    integer my_rank
    integer NPROCS
    integer source
    integer dest
    integer tag
    character*100 message
    character*10  rank
    integer status(MPI_STATUS_SIZE)
    integer ierr

c   Start MPI
    CALL MPI_Init(ierr)

c   Find out process rank
    CALL MPI_Comm_rank(MPI_COMM_WORLD, my_rank,ierr)

c   Find out the number of processes
    CALL MPI_Comm_size(MPI_COMM_WORLD, NPROCS,ierr)

    if (my_rank.ne.0) then

c   Create Message
    write(rank,100) my_rank
100 format(I1)
    message = 'Hello from process ' //  rank
  &amp;             // '!'
    dest = 0
    tag = 0
    CALL MPI_SEND(message, 100, MPI_CHARACTER,
  &amp;             dest, tag, MPI_COMM_WORLD, ierr)
    else
    do 200 source = 1, NPROCS-1
        tag = 0
    CALL MPI_RECV(message, 100, MPI_CHARACTER,
  &amp;     source,tag, MPI_COMM_WORLD, status, ierr)
    write(*,*) message
200 continue
    endif

c   Shutdown MPI
    CALL MPI_FINALIZE(IERR)
    end

In Fortran, MPI programs require the include file mpif.h. Status is
an array of integers of length MPI_STATUS_SIZE which is defined
in the file mpif.h. It is used to return the status of the MPI
communication subroutines. Information on MPI_SOURCE, MPI_TAG,
and MPI_ERROR is obtainable from Status. For now, just think of
the status variable as the place where MPI puts the error codes
for its subroutines.
<p>
Now we will start looking at the MPI subroutines used in this
program. The first is MPI_INIT which has the following
definition:

    CALL MPI_INIT(ierr)
    integer ierr

 MPI_INIT must be the first MPI  call in your program, as it initializes the state of the
program for all other MPI calls. Although the call to MPI_INIT
allows the passing of the command line parameters, their use is
not defined in the MPI standard. This means that using them is not
necessarily portable, and that they should be used with caution.
Their use is beyond the scope of this class. Also note that for
most installations, you can get information on the MPI functions
by using the man command.
<p>
With the next call we begin to delve into some of the mechanisms
of MPI programming.
<p>

c   Find out process rank
    CALL MPI_COMM_RANK(MPI_COMM_WORLD,my_rank,ierr)

c   Find out the number of processes
    CALL MPI_COMM_SIZE(MPI_COMM_WORLD,NPROCS,ierr)

<p>
Both MPI_COMM_RANK and MPI_COMM_SIZE have as their first
parameter the constant MPI_COMM_WORLD, which is of type
MPI_COMM. An MPI_COMM is the data type used to reference a it
communicator. A communicator indexcommunicator is a collection
of processes. As your programs and the underlying tasks become
more complicated, you may need to set up different groups of
processors to accomplish different tasks and may need to create
your own communicators. MPI by default sets up the global
communicator MPI_COMM_WORLD.  The MPI_COMM_RANK command
returns the process number or "rank" within the communicator.
MPI_COMM_SIZE puts the size of the given communicator into the
location pointed to by the second parameter.  The rank of the
process and the communicator's size are often used to control the
local flow of the program. We can see this in the next code
segment.
<p>

    if (my_rank.ne.0) then
c   Create Message
    write(rank,100) my_rank
100     format(I1)
    message = 'Hello from process ' //  rank
  &amp;             // '!'
    dest = 0
    tag = 0
    CALL MPI_SEND(message, 100, MPI_CHARACTER,
  &amp;             dest, tag, MPI_COMM_WORLD, ierr)
    else
    do 200 source = 1, NPROCS-1
        tag = 0
    CALL MPI_RECV(message, 100, MPI_CHARACTER,
  &amp;     source,tag, MPI_COMM_WORLD, status, ierr)
    write(*,*) message

<p>
In this snippet we see two very common MPI constructions.  First
the it if .. else construction where one (or more) process(es)
are executing one set of instructions, and another set of
processes are executing another. In this case we see that each
process other than the root process (rank = 0) is sending a
message.  Meanwhile, the root process is receiving messages in a
DO loop which runs from 1 to the size of the communicator. Note
that there is nothing in this code that forces an order on the
communications from the non-root processes.  Rather they will each
run the code asynchronously.  One might ask how is it that the
root process is able to receive the messages in the correct order?
To answer that question, we must take a more in depth look at the
it MPI_RECV and it MPI_SEND commands. This is the subject
of the next , but we will take a brief look at these
commands here, paying particular attention to the parameter types
and what they mean.
<p>
The MPI_Send command has the definition:

    call MPI_SEND (buf,icount,MPI_Datatype,idest,
  &amp;                  itag,MPI_COMM,ierr)
    integer icount,idest,itag,ierr

<p>
begindescription
   <br> [buf] This is initial address of the send buffer, in our case it is
the beginning of the string message.
   <br> [icount] number of elements in send buffer. The count is not the number of bytes
but number of <br>s.  This allows more complex data types to be
handled easily, and maintains portability.
   <br> [datatype] Datatype of each send buffer element.  Note that this is
not a standard Fortran datatype but one of the data types defined
by MPI. Although MPI has many datatypes and functions for
manipulating them, our examples will draw from the basic types
given in the following list.
   <br>
      <br> MPI_CHARACTER
      <br> MPI_REAL
      <br> MPI_INTEGER
      <br> MPI_DOUBLE_PRECISION
      <br> MPI_LOGICAL
      <br> MPI_REAL8
      <br> MPI_REAL4
      <br> MPI_INTEGER4
      <br> MPI_BYTE
      <br> MPI_PACKED
      <br> MPI_COMPLEX
      <br> MPI_DOUBLE_COMPLEX
   
   <br> [idest] Rank of the destination
   <br> [itag] The use of the message tag is left to the program. It may be
used to classify messages
   <br> [comm] Communicator
   <br> [ierr] MPI error number (0=no error)
enddescription
<p>
The MPI_RECV has the  definition:

    call MPI_RECV (buf,icount,MPI_Datatype,isource,
 &amp;                   itag,MPI_COMM,istatus,ierr)
    integer  icount,isource,itag,ierr

Let's take a look at the differences between MPI_SEND and
MPI_RECV. The it buf in the MPI_RECV call is the initial
address of the receive buffer instead of the send buffer.  We have
replaced idest or the destination of the message with the source
of the message. MPI_RECV also returns a Status variable as
described above.
<p>
With just a little more information we can now answer the
question, how does the root process receive the messages in order.
MPI buffers messages. Although MPI does not guarantee that the
messages from different processes arrive in any specific order,
the root process reads them  from the buffer in processor number
order. MPI does however ensure that messages from the same
processor do arrive in order.  We will explore other types of
point-to-point communications and their details in the following
.
<p>
<br>Compiling and running MPI programs
To compile MPI programs you must make sure that the
MPI_HOME/include directory is in your include path, and that the
MPI_HOME/lib directory is in your library path.  On the lab
machines this should be the default configuration. If these
requirements are met the program above can be compiled with the
command:

   g77 -L/usr/local/mpich/lib hello.o 
		 -ffree-form -o hello  -lmpich

On most installations of MPI there is some script to make sure
that you have include the correct libraries an paths.  For our
machines the command is it mpif77.  So you can replace the above
command with:

   mpif77 -ffree-form -o HelloWorld HelloWorld.f

<p>
Once the program is compiled you can use the it mpirun command
to run the program.  The following example should work on your lab
machine:

mpirun -np 4 -machinefile /usr/local/nodes HelloWorld

<p>
<br>A note on output
Getting output from an MPI program is not as straightforward as it
is in serial programming.  This is a topic of much discussion, and
research.  In general if you put a print statement into an MPI
program, it will not necessarily print in some convenient fashion.
Remember that each node operates independently. Suppose that an
MPI program has the following code
<p>

    write(*,*) 'my rank is',myrank
 ... processing code ...
    write(*,*) 'my value is',REAL(myrank)

The output from this bit of code could be in any order.

my rank is 0
my rank is 1
my rank is 2
my value is 0.0
my value is 1.0
my value is 2.0

or

my rank is 0
my value is 0.0
my rank is 2
my rank is 1
my value is 1.0
my value is 2.0

The only thing that you can be sure of is that the program will
run sequentially on each processor.  There are advanced methods of
I/O for MPI, and there are some parallel I/O calls that you may
want to explore as you become more familiar with MPI.  For now you
should do one of two things.  If you want to have some nice tidy
output send messages to the root process and print from there, or
make sure that each line of output includes the rank of the
process so that you can be sure of which process is doing the
output.
<p>
<br>Exercises
label:basicMPIex
<br>
   <br> Hello Neighbor - Modify the Hello World Program so that each processor
sends a message to the processor of the next highest rank, and
receives a message from the next lower rank.  The root process 0
should not receive a message, and the processor with the largest
rank should not send a message. After all of the messages are sent
and received all of the non root processes should send the root
process a message with their received message.  The output should
look something like:

process 1 received message Hello from process 0
process 2 received message Hello from process 1
   ...

   <br> Advanced Exercise - On each non-root processor define a one
dimensional array of integers and fill it with the product of the
processor number and the <br> of the location in the array.  Send
this vector to root. On the root processor receive the vectors
into rows of a matrix.  For simplicity, assume that there are four
processors and each vector has length 3.  Then print out the
matrix from the root process. The output should look like:

   0 1 2
   0 2 4
   0 3 6


<p>
 Point-to-Point Communications
In this , we will examine point-to-point message passing
which allows data transfer from one process to another.  Unlike
collective communications, point-to-point message passing involves
only a pair of processes.
<p>
Sending a scalar variable or an array from one process requires
calling an mpi send subroutine. This initiates data transfer from
the user buffer to the system buffer. The corresponding receive
call, on the other hand, allows data to be copied from the system
buffer to the user buffer in the destination process. There is a
variety of mpi send subroutines allowing communication in
different modes  - synchronous, buffered, ready, standard blocking
and non-blocking.  Unlike send, there are only two types of
receive subroutines: standard blocking and nonblocking. Here, we
will focus on blocking and nonblocking communications, as they are
the most commonly used modes.
<p>
When we use the blocking send subroutine, MPI_SEND, control does
not return to the program until the data transfer to the system
buffer is complete. Similarly, control returns from the blocking
receive subroutine, MPI_RECV only after the data is copied to the
user buffer. On the other hand, nonblocking communication
subroutines, MPI_ISEND and MPI_IRECV, indicate that the data
transfer has only begun. Control immediately returns to the
program while data transfer continues in the background. Note that
incorrect communications occur if we change the buffer content
before data transfer is complete. Therefore, somewhere in the
program, we have to make sure that the communication is over by
calling  MPI_WAIT. The format for  MPI_WAIT is as follows:
<p>

    CALL MPI_WAIT(IREQUEST,ISTATUS,IERR)
    Irequest    Request Identifier
    Istatus     Status Object
    Ierr        Fortran Return code

<p>
Now, let us take a look at the following example program where a
different scalar variable is initialized on each process.  The
processes communicate and calculate the sum of these variables.
<p>

        PROGRAM COMMUNICATION
        INCLUDE  'mpif.h'
        DOUBLE PRECISION a,b,c
c       Start MPI
        CALL MPI_INIT(IERR)
c       Number of processes
        CALL MPI_COMM_SIZE(MPI_COMM_WORLD,
     &amp;                       NPROCS,IERR)
c       Process rank
        CALL MPI_COMM_RANK(MPI_COMM_WORLD,
     &amp;                        MYRANK,IERR)
c       Define next and previous processes
        INEXT=MYRANK+1
        IPREV=MYRANK-1
c        Define Null processes
        IF (MYRANK.EQ.(NPROCS-1))
     &amp;       INEXT=MPI_PROC_NULL
        IF(MYRANK.EQ.0)IPREV=MPI_PROC_NULL

c       Initialize a in process 0 and b in process 1
        if (myrank.eq.0) a=1.50d0
        if (myrank.eq.1) b=2.50d0

c       Data exchange
         CALL MPI_ISEND(a,1,MPI_DOUBLE_PRECISION,
     &amp;  INEXT,1,MPI_COMM_WORLD,ISEND1,IERR)

        CALL MPI_ISEND(b,1,MPI_DOUBLE_PRECISION,
     &amp;  IPREV,1,MPI_COMM_WORLD,ISEND2,IERR)

        CALL MPI_IRECV(a,1,MPI_DOUBLE_PRECISION,
     &amp;  IPREV,1,MPI_COMM_WORLD,IRECV1,IERR)

        CALL MPI_IRECV(b,1,MPI_DOUBLE_PRECISION,
     &amp;  INEXT,1,MPI_COMM_WORLD,IRECV2,IERR)

c       Calculate c  and d before MPI_WAIT
        d=(5.0d0)**(2.d0)+5.0d0
        c=a+b+d
        write(*,*) c,d,myrank

        CALL MPI_WAIT(ISEND1,ISTATUS,IERR)
        CALL MPI_WAIT(ISEND2,ISTATUS,IERR)
        CALL MPI_WAIT (IRECV1,ISTATUS,IERR)
        CALL MPI_WAIT (IRECV2,ISTATUS,IERR)

c       Calculate c after MPI_WAIT
        c=a+b+d

        write(*,*) c,d, '**',myrank

c       Shutdown MPI
        CALL MPI_FINALIZE(IERR)

        END

<p>
This program generates a wrong value for c when it is calculated
before the MPI_WAIT call.  MPI_WAIT is used to block both
sending and receiving processes until the communication is
complete. Since the variable d can be calculated correctly during
data exchange, it is safe to post MPI_WAIT calls afterwards. On
the other hand, placing MPI_WAIT just after the immediate Send
and Receive calls would be the same as using blocking
communications. Please note that, to reduce synchronization
overhead, we should post MPI_WAIT in the program as late as
possible.
<p>
We use immediate calls because they are faster than blocking
communications. Also, blocking calls may fail when the sent
message is too large.
<p>
<br>Transferring Data from Arrays
We specify the location of the first element to be sent or
received when we call MPI communication subroutines. For a
successful communication, rest of the elements to be transferred
must be contiguous in the memory. Since   Fortran stores the
elements of a two-dimensional array in column major order, sending
a column of an array is straightforward.  Let us examine the
following program that computes the elapsed time for the data
exchange between two processes.
<p>

        PROGRAM COMMUNICATION2
        INCLUDE 'mpif.h'
        DOUBLE PRECISION A,B,T1,T2,RESON
        DIMENSION A(2500,2500),B(2500,2500)

        CALL MPI_INIT(IERR)

        CALL MPI_COMM_SIZE(MPI_COMM_WORLD,
     &amp;                       NPROCS,IERR)

        CALL MPI_COMM_RANK(MPI_COMM_WORLD,
     &amp;                       MYRANK,IERR)

        RESON=MPI_Wtick()
        write(*,*) reson, 'clock resolution'

        IF (MYRANK.EQ.0) THEN
        DO I=1,2500
        DO j=1,2500
        A(I,J)=1.0
        ENDDO
        ENDDO
        ENDIF

        IF (MYRANK.EQ.1) THEN
        DO I=1,2500
        DO J=1,2500
        B(I,J)=2.0
        ENDDO
        ENDDO
        ENDIF

        CALL MPI_BARRIER(MPI_COMM_WORLD,ierr)
        IF (MYRANK.EQ.0) THEN
        T1=MPI_WTIME()

        CALL MPI_SEND(A(1,1),5000,
   &amp;    MPI_DOUBLE_PRECISION, 1,1,
   &amp;    MPI_COMM_WORLD,IERR)
        CALL MPI_RECV(B(1,1),5000,
   &amp;    MPI_DOUBLE_PRECISION,1,1,
   &amp;     MPI_COMM_WORLD,IRECV1,IERR)

        T2=MPI_WTIME()
        write(*,*) t2-t1,myrank,'t2'
        ENDIF

        IF (MYRANK.EQ.1) THEN
        T1=MPI_WTIME()

        CALL MPI_SEND(B(1,1),5000,
  &amp;     MPI_DOUBLE_PRECISION, 0,1,
  &amp;     MPI_COMM_WORLD,IERR)
        CALL MPI_RECV(A(1,1),5000,
  &amp;     MPI_DOUBLE_PRECISION,0,1,
  &amp;     MPI_COMM_WORLD,IRECV2,IERR)
        T2=MPI_WTIME()
        write(*,*) t2-t1,myrank
        ENDIF
        CALL MPI_FINALIZE(IERR)
        END

First, let us explain briefly some of the subroutines we have used
for the first time. MPI_WTICK is used to determine the clock
resolution and MPI_WTIME gives the elapsed time.
<p>
The MPI_BARRIER subroutine blocks each process until each one has
called it. It is used for synchronization. In other words,  it
ensures that the processes start sending and receiving at the same
time. MPI_BARRIER can be used for blocking multiple processes; it
is a collective communication subroutine.  We will see more about
collective communications in the next .
<p>
In this program, each process transfers the first and second
columns of the array initialized on them. If we increased the
number of columns to be transferred more and more, MPI_SEND and
MPI_RECEIVE would eventually fail. In this case, non-blocking
calls would still be working.
sub<br>Derived Data Types
Now, let us see how to transfer rows in an array.  A new data type
must be defined in order to send and receive rows because this
time the data is not contiguous in the memory. The following
Send/Receive pair can be used to transfer the first row of the
following array.

            1 2 3 4
            1 2 3 4
            1 2 3 4
            1 2 3 4

<p>

        CALL MPI_TYPE_VECTOR(4,1,4,
   &amp;    MPI_DOUBLE_PRECISION,rowtype,ierr)
        CALL MPI_TYPE_COMMIT(ROWTYPE,IERR)

        IF (MYRANK.EQ.0) THEN
         CALL MPI_SEND(A(1,1),1,rowtype,
   &amp;     1,1,MPI_COMM_WORLD,ISEND2,IERR)
        ENDIF

        IF (MYRANK.EQ.1) THEN
        CALL MPI_RECV(A(1,1),1,rowtype,
   &amp;    0,1,MPI_COMM_WORLD,IRECV2,IERR)

        CALL MPI_TYPE_FREE(rowtype,ierr)

<p>
The MPI_TYPE_VECTOR subroutine is used to define a new data type
representing equally spaced blocks.  It has the following format:
<p>

    CALL MPI_TYPE_VECTOR(COUNT, BLOCKLENGTH,
  &amp; STRIDE, OLDTYPE,NEWTYPE,IERROR)

COUNT           Number of blocks
BLOCKLENGTH     Number of elements in each block
STRIDE          Number of elements between
                two succesive blocks
OLDTYPE         Old data type
NEWTYPE         New data type
IERR            Fortran return code

<p>
The MPI_TYPE_COMMIT makes the new data type ready to be used in
communication. The new data type is freed by the MPI_TYPE_FREE
call. In other words, the MPI_TYPE_FREE routine sets the new
data type to MPI_DATATYPE_NULL.
<p>
<br>Exercises
<br>
<br> On each process, define a 4X4  array.  The first process
will have 1s in the first column, the second process will have 2s
in the second column and so on. The rest of the elements of the
array will be zero. Using blocking communication subroutines,
complete the array on each process. Assume that the number of
processes is 4. The output should look like as follows.
<p>

            1 2 3 4
            1 2 3 4
            1 2 3 4
            1 2 3 4

Rewrite the program using non-blocking communications.
<p>
<br> Advanced Exercise: Modify the array of the previous exercise
such that only one row should contain nonzero elements initially.
Complete the array on each process using derived data types and
point to point communications.

<p>
Collective Communications
label:collective_communications Until this point we've
only discussed communications coming from a single process and
going to a single process.  MPI also contains it collective
communications indexcollective communications which loosely
defined are those communications that involve multiple processors
on the sending end, the receiving end or both. The MPI_Barrier
command that was described in the last , is often included
as a collective communication. In the following s we will
describe some of the most commonly used communications of this
type.  The reader should be aware that this is a rich, complex and
useful area within MPI, and these notes barely scratch the
surface.
<p>
<br>One to All
<br>:bcast To send messages from one process to all
other processes MPI contains the function MPI_BCAST.
indexMPI_BCAST The format for MPI_BCAST is
<p>

    CALL MPI_BCAST(buffer,icount,MPI_DATATYPE,
  &amp; iroot,MPI_COMM,ierr)
    integer icount,iroot,ierr

<p>
There are several differences between MPI_BCAST and the
point-to-point communications that we have looked at in the
previous s.  First both the sender and the receivers use
the same function call. Root in the case of MPI_BCAST is the rank
of the process sending and it must be the same on all processes or
there will be an error.
<p>
It is important to understand that although you can accomplish the
same data transfer by using individual sends and receives, using
MPI_BCAST is more efficient.  This is generally true of the
collective communications.  Let's take a brief look at why.  When
you do individual sends and receives, at each iteration of the
loop there is one message being sent from the sending process to
each of the receiving processes.  There are other possible methods
of getting the data to each process that are more efficient. Let's
assume for the sake of simplicity that the root process in our
communication is process 0, and we have 8 nodes. In this case we
could send the communications in the manner depicted in Figure
reffig:bcast.
<p>
beginfigure[H]
    centering
    epsffilebcast.eps
<p>
caption A more efficient communication scheme
    labelfig:bcast
endfigure
<p>
Notice that this completes the communication in three time steps
instead of the eight needed by sending all messages from root.
This is not to say that TCP/IP communications are this simple, or
that there are not more efficient schemes. The efficiency of such
a scheme is dependent on the underlying network topology.
Fortunately, we don't have to come up with an efficient scheme
each time we want to distribute data.  The implementations of
MPI_BCAST handle the details for us.  This is especially
important when one considers portability issues.  Without using
the MPI built in routines, you would have to determine the best
scheme each time you wanted to run the program in a different
environment, or even a different number of processors.
<p>
<br>All to one
<br>:reduce So you are probably thinking that if MPI
has an efficient method of broadcasting from one process to all of
the others that there should be some way of collecting data from
all of the nodes into one.  And there are several. The first ones
that we will look at involve reduction operations.  For example
suppose that you have a value on each processor and that you
wanted to get a global sum of these values.  If we send all of the
data to the root node by using individual calls we have created
several bottlenecks in the program. The communications must be
received sequentially at the root node.  Also, once the data is
collected the other processors must wait until the root processor
is finished with the calculation before they can proceed. (If they
need the result.)  The function MPI_Reduce takes care of the
first of these problem.
<p>

    CALL MPI_REDUCE(sendbuf,recvbuf,icount,
  &amp; MPI_Datatype,MPI_Op,iroot,MPI_Comm,ierr)
    integer icount,iroot,ierr

<p>
Lets take a look at an example. Assume that all of the variables
are defined appropriately.

    CALL MPI_REDUCE(val,total,1,MPI_INTEGER,
  &amp; MPI_SUM,0,MPI_COMM_WORLD,ierr)

<p>
Each process calls MPI_Reduce with the same parameters.  Even
though the sum is accumulated only on process 0. After the call
above, the variable total will contain the global sum.  What if
you want to do some other operation than summation? MPI predefines
several operations for the parameter MPI_Op. It can take on the
following values.
begindescription
    <br> [MPI_MAX] maximum
    <br> [MPI_MIN] minimum
    <br> [MPI_SUM] sum
    <br> [MPI_PROD] product
    <br> [MPI_LAND] logical and
    <br> [MPI_BAND] bit-wise and
    <br> [MPI_LOR] logical or
    <br> [MPI_BOR] bit-wise or
    <br> [MPI_LXOR] logical xor
    <br> [MPI_BXOR] bit-wise xor
    <br> [MPI_MAXLOC] max value and location of maximum
    <br> [MPI_MINLOC] min value and location of minimum
enddescription
<p>
The operators MPI_MAXLOC and MPI_MINLOC have predefined MPI
datatypes to be able to return the value and the location.
<p>
While MPI_Reduce solves the problem of efficiently communicating
the data to the root node it leaves open the question of how to
distribute the result if it is needed on all of the processors. We
could follow the call to MPI_Reduce with a call to MPI_Bcast,
but this isn't the most efficient method. Instead MPI uses a
communication structure called the it butterfly which
communicates the results of partial operations in such a way that
at the end of the call all of the processors have the result.  The
details of this communication scheme are beyond the scope of these
notes, but it should suffice at this stage to just assume that for
doing one of the global reduction operations and having the result
be available to all of the processors, MPI_Allreduce is the
function of choice. The definition of MPI_Allreduce is given
below.
<p>

    call MPI_ALLREDUCE(sendbuf,recvbuf,icount,
  &amp;     MPI_Datatype,MPI_Op,MPI_Comm,ierr)
    integer icount,ierr

<p>
<br>Scatter and Gather
<br>:scattergather We have looked at collective
communications that take the same data and communicate it to all
processors, and those that reduce data from all processes to one.
But these communication functions will not allow us to send different
information to each process.  Nor will they allow us to collect
separate bits of information from all of the processes onto one.
For these tasks we can use MPI_SCATTER and MPI_GATHER.
<p>

    CALL MPI_SCATTER(SNDBUF,ISCOUNT,MPI_DATATYPE,
  &amp; RECVBUF,IRCOUNT,MPI_DATATYPE,IROOT,MPI_COM,
  &amp;                  IERR)
    integer  iscount,ircount,iroot,ierr

    CALL MPI_GATHER(SNDBUF,ISCOUNT,MPI_DATATYPE,
  &amp; RECVBUF,IRCOUNT,MPI_DATATYPE,IROOT,MPI_COM,
  &amp;                 IERR)
    integer  iscount,ircount,iroot,ierr

<p>
The meanings of these parameters are similar to previous commands
that we have studied.  The iscount is usually the same as the
ircount, and the send datatype is usually the same as the receive
datatype. We can look at the following example to see how
MPI_Scatter works.
<p>

        PROGRAM SCATTER
        INCLUDE 'mpif.h'

        real vec
        dimension vec(4)
        CALL MPI_INIT(ierr)
        CALL MPI_COMM_SIZE(MPI_COMM_WORLD,NPROCS,
     &amp;                      IERR)

        CALL MPI_COMM_RANK(MPI_COMM_WORLD,MYRANK,
     &amp;                       IERR)

        if (myrank.eq.0) then
        do i=0,3
        vec(i+1)=i*2.0
        enddo
        endif
        CALL MPI_SCATTER(vec,1,MPI_INTEGER,vec,1,
     &amp;    MPI_INTEGER,0,MPI_COMM_WORLD,IERR)

        write(*,*) vec(1),myrank
        CALL    MPI_FINALIZE(ierr)
        end

<p>
This code will distribute the each of the entries of vector vec to
the processes in MPI_COMM_WORLD.  Figure reffig:scat shows
the effects of the MPI_Scatter command on the memory for each
process.
<p>
beginfigure[H]
    centering
    epsffilescat.eps
<p>
caption The effects of MPI_Scatter
    labelfig:scat
endfigure
MPI_Gather is in some sense the inverse operation to
MPI_Scatter.  Instead of distributing values, it gathers them
together.  The following code and Figure reffig:gather show the
effects of the MPI_Gather operation.
<p>

        PROGRAM GATHER
        INCLUDE 'mpif.h'

        real vec
        dimension vec(4)
        CALL MPI_INIT(ierr)
        CALL MPI_COMM_SIZE(MPI_COMM_WORLD,
    &amp;                        NPROCS,IERR)

        CALL MPI_COMM_RANK(MPI_COMM_WORLD,
    &amp;                        MYRANK,IERR)

        if (myrank.ne.0) vec(1)= myrank*2.0

        CALL MPI_GATHER(vec,1,MPI_INTEGER,vec,1,
     &amp;    MPI_INTEGER,0,MPI_COMM_WORLD,IERR)

        if (myrank.eq.0) then
        do i=0,3
        write(*,*) vec(i+1)
        enddo
        endif
        CALL  MPI_FINALIZE(ierr)
        end

<p>
beginfigure[H]
    centering
    epsffilegather.eps
<p>
caption The effects of MPI_Gather
    labelfig:gather
endfigure
<br>Exercises
<br>:reductionEx
<br>
   <br> Write a program using MPI_Bcast and MPI_Reduce to calculate the
dot product of two vectors.  For simplicity, initialize and assign
values to the integer vectors of length 20 (Do this only the root
process and assign the values as you wish). Assume the the the
number of processors evenly divides 20.
   <br> Matrix-Vector multiplication. For this example assume that you will be using 4 processors.  On on the root process initialize a 4x4 matrix and 
a 4x1 vector.  Multiply the matrix by the 
vector using MPI_Scatter to distribute the matrix  and MPI_Bcast to distribute
the vector to the non-root processes.  
Then use MPI_Gather to collect the result.
   <br> Advanced Exercise - Write a program using newline MPI_AllReduce to
calculate the integral of <IMG
 WIDTH="45" HEIGHT="15" ALIGN="MIDDLE" BORDER="0"
 SRC="img33.png"
 ALT="$ f(x)=x^2$">
 in the interval 0 to 12 using
the Trapezoid rule. Assume  4 processors, you can use the
intervals <!-- MATH
 $[a,b] = [p*3,(p+1)*3]$
 -->
<IMG
 WIDTH="70" HEIGHT="32" ALIGN="MIDDLE" BORDER="0"
 SRC="img34.png"
 ALT="$ [a,b] = [p*3,(p+1)*3]$">
. Can you extend this program to
handle any interval with any number of processes?

Putting All Together: A Diffusion Problem in MPI
In this , we will apply what we have  learned to a two
dimensional diffusion problem for which  the prototype system is
shown in Figure reffig:figure1.
Here, the concentration of a
solute in a liquid is held constant at 1 at the boundaries of a
square domain. Initially, the concentration is  2 inside, except a
small square in the middle.
beginfigure[H]
centering
includegraphics figure1.eps
captionThe Prototype System
labelfig:figure1
endfigure
As Fick's Law states, the solute will diffuse from high
concentration to  low concentration region. To determine the
concentration at any point and time, we need to solve the
following partial differential equation.Here, C stands for
concentration; t for time; x and y for space dimensions; and D for
diffusivity.
<p>
beginequation
 fracpartial Cpartial t  = Dbigg{fracpartial ^2 Cpartial x^2+fracpartial ^2 Cpartial y^2bigg}
endequation
linebreak
<p>
We will use the explicit finite difference method to solve
this equation. The formulation is as follows:
beginfigure[H]
centering
includegraphics[width=9cm] figure2.eps
captionDiscretization of the Domain
endfigure
<p>
Second order partial derivatives in the x and y
direction:
<p>
beginequation
fracpartial^2 Cpartial x^2  = frac1triangle x^2bigg{C^k_i+1,j-2C^k_i,j+C^k_i-1,j  bigg}
endequation
<p>
beginequation
fracpartial^2 Cpartial y^2  = frac1triangle y^2bigg{C^k_i,j+1-2C^k_i,j+C^k_i,j-1  bigg}
endequation
linebreak
<p>
Time derivative:
<p>
beginequation
 fracpartial Cpartial t  = frac1triangle tbigg{C^k+1_i,j-C^k_i,j  bigg}
endequation
linebreak
<p>
The partial differential equation in terms of finite difference
formulas:
<p>
beginalign
 frac1triangle tbig(C^k+1_i,j-C^k_i,jbig)  &amp;=D frac1triangle x^2bigg{C^k_i+1,j-2C^k_i,j+C^k_i-1,j bigg}notag 
<BR> &amp;+D frac1triangle y^2bigg{C^k_i,j+1-2C^k_i,j+C^k_i,j-1bigg}
endalign
<p>
Rearranging Eq.5.5,
<p>
beginalign
C^k+1_i,j =C^k_i,j&amp;+D fractriangle ttriangle  x^2bigg{C^k_i+1,j-2C^k_i,j+C^k_i-1,jbigg}notag
<BR>&amp;+D fractriangle ttriangle
y^2bigg{C^k_i,j+1-2C^k_i,j+C^k_i,j-1bigg}
endalign
linebreak
<p>
The explicit finite difference method  requires small time steps in order to
 overcome the stability problem which makes it   computationally
 expensive . However, this method is simple and easy to parallelize. The
 square domain is divided among two processes  in Figure reffig:figure3.
  Each process is responsible for one rectangular grid and
 the boundary elements are transferred to neighboring processes through message
 passing. Note that, in columnwise distribution, the
 boundary elements are contiguous in the memory and they can be
 transferred without using derived data types.
beginfigure[H]
centering
includegraphics [width=6cm] figure3.eps
captionDividing the Domain between Two Processes 
labelfig:figure3
endfigure
<p>
Now let us examine the program to see how  to divide the domain
among the processes; express the initial and boundary conditions
in a parallel program; and also, generate output files.
<p>

    PROGRAM DIFFUSION

    include  'mpif.h'

c   N,M: Number of grids in the x and y
c   directions
c   root: Rank of the process to which array
c   elements with an initial value of 5 are
c   mapped
c   FLD,WKSP:Concentration of the solute
c   DF:Diffusivity
c   L:Length of one side of the square domain

    integer N, M, root,NT
    integer COUNT,I,J
    double precision FLD, WKSP
    double precision DELTA,DELTAT,DELTAX
    double precision DELTAY,DELTA1,DELTA2
    double precision DF,L,T

c   Variables used for opening output files
    character*12 hostname
    integer status, hostnm
    character*32 filename

c   Variables used for timing
    double precision FUNCTION DSECNDS
    double precision XL, Y1,Y2

c   Control parameter
    logical  done

    dimension   FLD(2401,2401),WKSP(2401,2401)
    integer ISTATUS(MPI_STATUS_SIZE)

c   Start the timer
    XL=0.0
    Y1=DSECNDS(XL)

    CALL MPI_INIT(IERR)

c   Initializing the parameters
    N=2401
    M=2401
    T=10.0d0
    NT=100
    DELTAT=T/NT
    L=100.0d0
    DELTAX=L/(N-1)
    DELTAY=L/(M-1)
    DELTA1=DELTAT/(DELTAX**2.0d0)
    DELTA2=DELTAT/(DELTAY**2.0d0)
    DF=(10.0d0**(-4.0d0))*25.0d0
    DONE=.FALSE.

    CALL MPI_COMM_SIZE(MPI_COMM_WORLD,NPROCS,
  &amp; IERR)
    CALL MPI_COMM_RANK(MPI_COMM_WORLD,MYRANK,
  &amp; IERR)

c   The subroutine  RANGE distributes the array
c   onto the processes.
c   JSTA and JEND stand for the first and the
c   last column mapped to each process.
    CALL RANGE (1,M,NPROCS,MYRANK,JSTA,JEND)

    ROOT=(NPROCS-1)/2
    JSTA2=JSTA
    JEND1=JEND
    IF (MYRANK.EQ.0) JSTA2=2
    IF (MYRANK.EQ.(NPROCS-1)) JEND1=M-1
    INEXT=MYRANK+1
    IPREV=MYRANK-1
    IF (MYRANK.EQ.(NPROCS-1))INEXT=MPI_PROC_NULL
    IF(MYRANK.EQ.0) IPREV=MPI_PROC_NULL

c   Initial Conditions
    DO J=JSTA2,JEND1
    DO I=2,N-1
    FLD(I,J)=2.0d0
    ENDDO
    ENDDO
    IF (MYRANK.EQ.ROOT) THEN
    DO J= 1190,1200
    DO I=1190,1200
    FLD(I,J)=5.0d0
    ENDDO
    ENDDO
    ENDIF

c   Boundary Conditions
    DO J=JSTA,JEND
    FLD(1,J)=1.0d0
    FLD(N,J)=1.0d0
    ENDDO
    IF (MYRANK.EQ.0) THEN
    DO I=1,N
    FLD(I,JSTA)=1.0d0
    ENDDO
    ENDIF
    IF (MYRANK.EQ.(NPROCS-1)) THEN
    DO I=1,N
    FLD(I,JEND)=1.0d0
    ENDDO
    ENDIF

c   Main Loop

    DO  COUNT=1,500
c   Transfer the boundary elements to
c   neigboring processes
    CALL MPI_ISEND(FLD(1,JEND),N,MPI_DOUBLE_
  &amp; PRECISION, inext,1,MPI_COMM_WORLD,ISEND1,IERR)
    CALL MPI_ISEND(FLD(1,JSTA),N,MPI_DOUBLE_
  &amp; PRECISION,iprev,1,MPI_COMM_WORLD,ISEND2,IERR)
    CALL MPI_IRECV(FLD(1,JSTA-1),N,MPI_DOUBLE_
  &amp; PRECISION,iprev,1,MPI_COMM_WORLD,IRECV1,IERR)
    CALL MPI_IRECV(FLD(1,JEND+1),N,MPI_DOUBLE_
  &amp;  PRECISION,inext,1,MPI_COMM_WORLD,IRECV2,IERR)

    CALL MPI_WAIT(ISEND1,ISTATUS,IERR)
    CALL MPI_WAIT(ISEND2,ISTATUS,IERR)
    CALL MPI_WAIT(IRECV1,ISTATUS,IERR)
    CALL MPI_WAIT(IRECV2,ISTATUS,IERR)

c   Updates the concentration using the finite
c   difference formula
    DO J=JSTA2,JEND1
    DO I=2,N-1
    WKSP(I,J)=FLD(I,J)+DELTA1*DF*(FLD(I+1,J)
  &amp; -2.0*FLD(I,J)+FLD(I-1,J))
  &amp; +DELTA2*DF*(FLD(I,J+1)-2.0*FLD(I,J)+FLD(I,J-1))
    ENDDO
    ENDDO

    DO J=JSTA2,JEND1
    DO I=2,N-1
    FLD(I,J)=WKSP(I,J)
    ENDDO
    ENDDO

c   Check whether the concentration in the middle
c   of the small square is below 2.5. If so, change
c   the control parameter "done" to true

    IF (MYRANK.EQ.ROOT) THEN
    WRITE(*,*) FLD(1195,1195), 'mdfld'
    IF (FLD(1195,1195).le.2.5) THEN
    WRITE(*,*) fld(1195,1195), 'mdfld'
    DONE=.TRUE.
    WRITE (*,*) done , myrank, 'done'
    ENDIF
    ENDIF

c   Collective Communication ("done" is transferred
c   from root to all processes)

    CALL MPI_BCAST(done,1,MPI_LOGICAL,root,
 &amp;  MPI_COMM_WORLD,ierr)
    IF (DONE) GO TO 100

    ENDDO

c   Prints the number of iterations necessary for
c   the concentration to go down to 2.5
100 WRITE(*,*) count, myrank, 'count'
c   Opens a file for each process for I/O as
c   "mpi.hostname"
    STATUS=HOSTNM(HOSTNAME)
    WRITE(*,*) HOSTNAME,MYRANK
    FILENAME='mpi.' // hostname
    OPEN(unit=myrank,file=filename,
  &amp; status='unknown')

    DO J=JSTA,JEND
    DO I=1,N
    WRITE(myrank,*) fld(i,j)
    ENDDO
    ENDDO

c   Terminates the parallel execution
    CALL MPI_FINALIZE(IERR)

c   Prints the elapsed time.
    Y2=DSECNDS(XL)
    Y2=Y2-Y1
    WRITE(*,*) Y2, 'seconds'

    END

    SUBROUTINE RANGE (n1,n2,nprocs,irank,ista,iend)
c   Number of columns that will be mapped to
c   each process
    iwork1=(n2-n1+1)/nprocs
c   Determines the offset
    iwork2=MOD(n2-n1+1,nprocs)
c   Distributes the extra columns to the processes
c   If mod()is 2 for example, an extra column will
c   be mapped to process 0 and process 1
    ista=irank*iwork1+n1+MIN(irank,iwork2)
    iend=ista+iwork1-1
    if(iwork2.gt.irank) iend=iend+1
    return
    end

<p>
The following figures show the initial and final states of the
system.
beginfigure[H]
includegraphics [width=13cm] result1.eps
captionSolute Concentration at t=0 
endfigure
beginfigure[H]
includegraphics [width=13cm] result2.eps
captionSolute Concentration after 366 iterations 
endfigure
<br>Exercises
<br>
<br> Modify the diffusion program for the following system.  Run
the code with 1,2,3 and 4 nodes and compare the execution times.
Try both non-blocking and blocking communications.
beginfigure[H]
centering
includegraphics [height=6cm]ex1.eps
captionThe Prototype System for Exercise1
endfigure
<br> Advanced Exercise. This time, there are two high
concentration regions as shown in the following Figure. Assume
that these regions are 10 grids away from the boundaries in the y
direction. The location of the squares in the x direction is the
same as before. Program should terminate when both of the
concentrations  go below 3.5. Again, run the program with different
numbers of nodes and compare the results.
beginfigure[H]
centering
includegraphics [height=6cm] ex2.eps
captionThe Prototype System for Exercise2 
endfigure

<p>
High Performance Fortran
HPF has been developed as a set of extensions to Fortran 90, to
provide parallel array and loop operations. Although HPF is
simpler than writing message passing code, it is not well-suited
to handle irregular data structures or control parallel programs.
In  an HPF program, each processor runs the same program on part
of the overall data. HPF directives are used for the distribution
of data among the processors. HPF supports both of the source
formatting (free and fixed forms) provided by Fortran.  An HPF
directive may have any of the following forms:
<p>

CHPF$   directive
!HPF$   directive
*HPF$   directive

<p>
The only form that can be used in  free source format for the HPF
directives is the !HPF$. If you use the !HPF$, your program will
be universally valid. Note that, these directives will only be
executed by HPF compilers. For a standard Fortran compiler, they
are just  comments and will be ignored. Now let us go over some of
the basic HPF directives used for data distribution and parallel
data execution.
<p>
<br>Data Distribution
 We will examine three important directives:
 PROCESSORS, DISTRIBUTE and ALIGN.
 sub<br> The PROCESSORS Directive
The PROCESSORS directive declares the number and rank of a
processor arrangement. The default is the number of processors
specified by the runtime command-line options.
 The syntax of a PROCESSORS definition is similar to the syntax of an array definition in Fortran. For example,
<p>

!HPF$   PROCESSORS  Example(4)

declares a set of 4 processors, named Example.

!HPF$  PROCESSORS Example(2,2)
\end {verbatim}
specifies 4 abstract processors in a 2x2 array. Note that the
processors-name can not be the same as a variable or constant
name. It is possible to inquire the number of processors from the
system using the HPF intrinsic functions NUMBER\_OF\_PROCESSORS()
and PROCESSOR\_SHAPE()

\sub<br> {The DISTRIBUTE Directive}

DISTRIBUTE specifies the mapping of data onto processors. The
syntax for this directive is as follows:

\begin{verbatim}
!HPF$   DISTRIBUTE ARRAY [BLOCK /CYCLIC]
c       [ONTO PROCESSORS]

<p>
HPF provides two different options to distribute arrays: BLOCK and
CYCLIC. BLOCK places successive elements in the same processors,
whereas  CYCLIC distributes the elements  in a round-robin
fashion. Block distributions are suitable for problems that have a
regular domain decomposition. Cyclic is good where the work load
is not the same for each  of the array. Note that
distributions must be selected in such a way to minimize
communications.  Now, let us take a look at the  following
examples:
<p>
Example 1: Assume  A is a  one dimensional array of 8 elements.

!HPF$   PROCESSORS P(4)
!HPF$   DISTRIBUTE A(BLOCK)  onto P

The array will be distributed  in the following fashion:
beginfigure[H]
centering
includegraphics  block1.eps
caption1-D Block Distribution 
endfigure
Example 2:

 !HPF$  PROCESSORS P(4)
 !HPF$  DISTRIBUTE A(CYCLIC)  onto P

beginfigure[H]
centering
includegraphics  cyclic.eps
caption1-D Cyclic Distribution 
endfigure
<p>
Example 3: B is a two
dimensional array B(4,4)

!HPF$ PROCESSORS P(4)
!HPF$  DISTRIBUTE  B(*,BLOCK)  onto P

beginfigure[H]
centering
 epsffileblock2.eps
caption(*,Block) Distribution 
endfigure
Example 4:

!HPF$   PROCESSORS P(2,2)
!HPF$   DISTRIBUTE B(BLOCK,BLOCK) onto P

beginfigure[H]
includegraphics  block3.eps
caption (Block,Block) Distribution 
endfigure
sub<br> The ALIGN Directive
<p>
The ALIGN directive specifies that a data object is to be mapped
in the same way as another one. Elements of arrays that are
aligned are mapped to the same abstract processor. The aim of the
alignment is to reduce communications between processors. Assume
that A, B are one dimensional arrays and each has 8 elements.

 !HPF$  PROCESSORS P(4)
 !HPF$  DISTRIBUTE A(BLOCK) ONTO P
 !HPF$  ALIGN  B(:) WITH A(:)

<p>
The alignment says that A(i) and B(i) must
be placed on the same processor. Now let us take a look at the
following example:

        REAL, DIMENSION(4)   :: A
        REAL, DIMENSION(8)   :: B
!HPF$   ALIGN A(i) WITH B(i*2)

<p>
In this case, A(1)
and B(2); A(2) and B(4); ...A(4) and B(8) will reside on the same
processor.
<p>
<br>Data Parallel Execution
 HPF provides data parallel execution by special array assignments.
 Here we will only examine
the FORALL statement.
<p>
sub<br>The FORALL Statement
FORALL is introduced as an alternative to the DO-loop. The
contents of a FORALL statement can be executed in any order.
FORALL gives identical results whether applied sequentially or in
parallel. Using FORALL is especially useful where assignments are
based on array indices.

    FORALL (I=1:1000,J=1:1000) A(I,J)=I+J

We can also use FORALL in the following form:

    FORALL (I=1:1000, J=1:1000)
    A(I,J)=I+J
    B(I,J)=A(I,J)
    END FORALL

<p>
<br>Additional Information on  HPF
<p>
Here, we will  look at the extrinsic procedures which are used to
call different languages and library functions in HPF.
<p>
sub<br>The HPF EXTRINSIC Routine
The HPF Extrinsic routine is provided to call a procedure beyond
the HPF language or style. This is called a local procedure
because HPF compiler calls it as though it were a serial routine
on each node. A local procedure can be written in F77, F90, C, C++
for example. It may be written even in HPF . An
EXTRINSIC(HPF_LOCAL) subroutine can call library modules such as
HPF_LOCAL_LIBRARY. This module includes some system inquiry
procedures such as  MY_PROCESSOR which returns the identifying
number of the calling physical processor.
<p>
Now let us examine the HPF version of the diffusion program.

    PROGRAM DIFFUSIONHPF
    IMPLICIT NONE

c   N,M: Number of grids in the x and y direction
c   FLD,WKSP:Concentration of the solute
c   DF: Diffusivity
c   L:Length of one side of the square domain

    INTEGER, PARAMETER :: N=2401, M=2401,
  &amp;                  MAXCOUNT=10000 ,no=10
    INTEGER   :: COUNT,I,nt,mynode
    DOUBLE PRECISION, DIMENSION(N,M) ::BOUND,
  &amp;          FLD,WKSP,CHANGE
    DOUBLE PRECISION ::DIFF,DF,L,T
    LOGICAL, DIMENSION (N,M) :: MASK
    DOUBLE PRECISION :: delta1,delta2,
  &amp;          deltat, deltax,deltay

c   Variables used for opening an output file
    INTEGER            :: unit_number
    CHARACTER (LEN=32) :: file_name

c    Variables used for timing
    CHARACTER (LEN = 12) :: DATE,TIMED,TIMED2
    INTEGER :: STARTTIME,COUNTRATE,ENDTIME
    REAL :: ELAPSEDTIME

c   Declares number of processors
!HPF$   PROCESSORS PRNUM(2,2)

c   Specifies the distribution of data
c   onto processes
!HPF$   DISTRIBUTE FLD(block,block) onto prnum

c   Alignment of data objects
!HPF$   ALIGN CHANGE(:,:) WITH FLD(:,:)
!HPF$   ALIGN WKSP(:,:) WITH FLD(:,:)
!HPF$   ALIGN MASK(:,:) WITH FLD(:,:)

c   Starts the timer
    CALL DATE_AND_TIME (DATE,TIMED)
    CALL SYSTEM_CLOCK(starttime, countrate)

c   Initialization of the parameters
    L=100.0d0
    T=10.0d0
    DF=(10.0d0**(-4.0d0))*25.0d0
    NT=100
    DELTAT=T/NT
    DELTAX=L/(N-1)
    DELTAY=L/(M-1)
    DELTA1=DELTAT/(DELTAX**2.0d0)
    DELTA2=DELTAT/(DELTAY**2.0d0)


c   OPEN (NO,FILE='dif.EX')

c   Boundary Values
    FLD=2.0d0
    FLD(UBOUND(FLD,DIM=1),:)=1.0d0  !S
    FLD(LBOUND(FLD,DIM=1),:)=1.0d0  !N
    FLD(:,UBOUND(FLD,DIM=2))=1.0d0  !E
    FLD(:,LBOUND(FLD,DIM=2))=1.0d0  !W

    FLD(1190:1200,1190:1200)=5.0d0

c   Assigns false to the Logical Variable
c   Mask at the boundaries
    MASK=.FALSE.
    MASK(2:N-1,2:M-1)=.TRUE.

c   Main Loop
    COUNT=0

    DO
    WHERE(MASK)
c   Updates the concentration using finite
c   difference formula and  CSHIFT
    WKSP=FLD+DELTA1*DF*(CSHIFT(FLD,1,1)+
     &amp;  CSHIFT(FLD,-1,1)-2.0*FLD)
     &amp;   +DELTA2*DF*(CSHIFT(FLD,1,2)+
     &amp;  CSHIFT(FLD,-1,2)-2.0*FLD)

    CHANGE=WKSP-FLD
    ENDWHERE
    FLD=FLD+CHANGE
        write(*,*) fld(1195,1195)

        COUNT=COUNT+1

c   Checks whether the concentration in the
c   middle of the small square is below 2.5

    IF (FLD(1195,1195).LE.2.5) go to 5500
    ENDDO
    PRINT*, TIMED,TIMED2
5500    PRINT*, count
    PRINT*, FLD(1195,1195),'MIDFLD'

c   Calls extrinsic subroutine to open
c   an output file for each process

500  call p_open (fld)
1922    FORMAT (F17.15)

c   Alternatively,  all data can be
c   written in a single file

    write(no,1922) fld

c   Stop the timer
    CALL DATE_AND_TIME (DATE,TIMED2)
    CALL SYSTEM_CLOCK(EndTime)
        ElapsedTime = REAL(EndTime -
     &amp;  StartTime) / REAL(CountRate)
        write(*,*) 'Wall clock time =
     &amp;  ', ElapsedTime, ' seconds'
        write (*,*) 'Start Time = ',TIMED
        write (*,*) 'End Time = ',TIMED2

    END PROGRAM DIFFUSIONHPF

    extrinsic(hpf_local) subroutine p_open (UD)

c   Allows using HPF_LOCAL_LIBRARY procedures
c   such as MY_PROCESSOR
    USE HPF_LOCAL_LIBRARY

    integer  :: mynode
    double precision, dimension(:,:),
 &amp;              intent(in) :: UD
    character(LEN=12) :: hostname
    character(LEN=32)  ::filename
    INTEGER  ::  hostnm, status

c   The library "lib3f.h" should be
c   included to be able to use the
c   function hostnm in an HPF code
    INCLUDE 'lib3f.h'

!hpf$   distribute *(block,block) :: UD

    mynode = MY_PROCESSOR()
    status=hostnm(hostname)
    write(*,*) hostname,mynode

c   Each processor opens an output file
c   as "filehpf.hostname
         filename='filehpf.' // hostname
1923     FORMAT (F17.15)

    OPEN(unit=mynode,file=filename,
     &amp;          status='unknown')
    write(mynode,1923)UD

    end subroutine p_open

<p>
Note that CSHIFT(array,shift,dimension) performs a circular shift
along a given dimension of an array
<p>

    1 2 3                  4 5 6
M=  4 5 6   CSHIFT(M,1,1)= 7 8 9
    7 8 9                  1 2 3
                   2 3 1
    CSHIFT(M,1,2)= 5 6 4
                   8 9 7

<br>Exercises
<br>
<br> Work on the problems of the previous  using HPF. Try
different distributions such as (*,Block), (Block,*) and
(Block,Block) on different numbers of processors. Compare the
execution times.

<p>
A Brief Introduction to PBS
label:pbs
PBS or it Portable Batch System is queuing software that controls the flow
of jobs on distributed systems.  PBS has the capability to have different queues
with different priorities.  One of the complications of running a parallel
machine is that not all jobs require all of the resources.  This means that
system resources would be idle if the system could only run one job at a time.
On the other hand, if there were no job control none of the jobs would run
efficiently.  PBS is flexible enough to handle many different configurations.
This  of the class is intended to give you an introduction to the basic
functions of PBS as we use them on our clusters. We will introduce the
several of the commands in the exercises at the end of this .
<br>Queues, qsub, and the submit scripts
Queues are at the heart of PBS.  There are several types and a long list of
possible settings for each type.  This can be used to sort jobs by various
resources, and assign them different priorities.  On our cluster we run with
only one queue called router.
<p>
Jobs are submitted to the queuing system using the command it qsub. In an
environment that has need of greater complexity, the command can be use to
control which queue a job enters, when the job is run, and controlling various
other aspects of a job.
<p>
While much of the job control can be accomplished using qsub command line
parameters, a preferable method is to use submission scripts.  These scripts
can set the environment and PBS variables to control the run. This is a
preferable method since it is much simpler to rerun a job with small changes.
<p>
Below is a sample script to run the HelloWorld program on 4 nodes.

#!/bin/sh
#PBS -l nodes=4
mpirun -np 4 -machinefile $PBS_NODEFILE HelloWorld
       -pgf77

If these lines were in a file called hello.pbs, then the program HelloWorld
could be submitted to the cluster with the command "qsub hello.pbs".
Although this is a simple file, there are a few points of interest.  The line
"#PBS -l nodes =4" is a PBS directive line.  Any line that starts with #PBS
is interpreted as a directive.  In this case it is telling PBS that it
needs 4 nodes to execute the program.  Notice that this number matches the
parameter -np in the mpirun line.  The number allocated by PBS must be greater
than or equal to the number requested by the mpirun command.  In the
mpirun line we have a PBS environment variable.  Although this is a shell
script PBS makes certain changes to the environment.  In this case, a list of
nodes that PBS is making available is stored in the $PBS_NODEFILE variable
and passed to mpirun.
<p>
If the above program were submitted with the qsub program above we would see
the following sequence of events.

&gt;qsub hello.pbs
&gt;100.mimir

This would be telling you that your job was assigned the number 100. When
the job was finished you would have two new files in this directory with
the names "hello.pbs.e100" and "hello.pbs.o100". The .e file contains the
output from standard error, and any errors that PBS encounters.  The .o file
contains the output from the submit script and the program.
<p>
The list below show some of the common modifications to the submit script
that you might want to use.
<p>
begindescription
<br>[#PBS -joe] Combine the error and output files.
<br>[#PBS -N ] Set the name of the job. This affects the name of the output
files.
<br>[#PBS -l] Sets the resource lists for the jobs -l can be followed by
a resource list which often includes the following <br>s.
   begin<br>ize
      <br> nodes - Specifies which may be followed by a formatted string specifying which nodes to use.
      <br> ncpus - Sets how many cpus are needed. This is more important with
SMP nodes, or in a pure SMP environment.
      <br> walltime - Sets an upper limit on the length of the job.
      <br> cputime - Sets an upper limit on the cpu time used for the job.
   end<br>ize
<br> [cd] Change the directory.
enddescription
<p>
There are many other options available and the complete Users Guide is available
on line from ftp.acomp.usf.edu.
<br>Exercises
<br>
<br> Create a submission script to run the diffusion program from the last
  on eight nodes and submit it by logging on to mimir and using qsub.
<br> While everyone is running their programs on mimir, log onto mimir and
investigate the commands qstat, pbs_stats,xpbsmon and xpbs. You may have to
rerun jobs if they all finish too fast.

<p>
Further Reading
label:addmat
begin<br>ize
<br> Books
begin<br>ize
   <br> it Using MPI:Portable Parallel Programming with the Message-Passing Interface by
   William Gropp, Ewing Lusk and Anthony Skjellum
   <br> it The High Performance Fortran Handbook by Charles H. Koelbel
end<br>ize
<br> On-line Tutorials
   begin<br>ize
   <br>  MPI - http://www.tacc.utexas.edu/ newline
			resources/user_guides/mpi/<br>.php
   <br>  HPF - http://www.jics.utk.edu/ newline
			HPF/HPFguide.html
   end<br>ize
end<br>ize
<p>


appendix

<p>VIM QUICK REFERENCE CARD
indexvi reference
label<p>:vimqrc
begintabular*4in rl
multicolumn2lbf Basic Movement
<BR>
hline
&amp;
<BR>
h l k j&amp;character left, right; line up, down
<BR>
b w&amp;word/token left, right
<BR>
ge e&amp;end of word/token left, right
<BR>{ } &amp;beginning of previous, next paragraph
<BR>( )&amp;beginning of previous, next sentence
<BR>
0 gm&amp;beginning, middle of line
<BR>^ $&amp;first, last character of line
<BR><IMG
 WIDTH="172" HEIGHT="29" ALIGN="BOTTOM" BORDER="0"
 SRC="img35.png"
 ALT="$ n$">
G <IMG
 WIDTH="172" HEIGHT="29" ALIGN="BOTTOM" BORDER="0"
 SRC="img35.png"
 ALT="$ n$">
gg&amp;line <IMG
 WIDTH="172" HEIGHT="29" ALIGN="BOTTOM" BORDER="0"
 SRC="img35.png"
 ALT="$ n$">
, default the last, first
<BR><IMG
 WIDTH="172" HEIGHT="29" ALIGN="BOTTOM" BORDER="0"
 SRC="img35.png"
 ALT="$ n$">
%&amp;percentage <IMG
 WIDTH="172" HEIGHT="29" ALIGN="BOTTOM" BORDER="0"
 SRC="img35.png"
 ALT="$ n$">
 of the file it(<IMG
 WIDTH="172" HEIGHT="29" ALIGN="BOTTOM" BORDER="0"
 SRC="img35.png"
 ALT="$ n$">
 must be provided)
<BR><IMG
 WIDTH="11" HEIGHT="11" ALIGN="MIDDLE" BORDER="0"
 SRC="img36.png"
 ALT="$ n\vert$">
&amp;column <IMG
 WIDTH="172" HEIGHT="29" ALIGN="BOTTOM" BORDER="0"
 SRC="img35.png"
 ALT="$ n$">
 of current line
<BR>%&amp;match of next brace, bracket, comment, tt#define
<BR><IMG
 WIDTH="172" HEIGHT="29" ALIGN="BOTTOM" BORDER="0"
 SRC="img35.png"
 ALT="$ n$">
H <IMG
 WIDTH="172" HEIGHT="29" ALIGN="BOTTOM" BORDER="0"
 SRC="img35.png"
 ALT="$ n$">
L&amp;line <IMG
 WIDTH="172" HEIGHT="29" ALIGN="BOTTOM" BORDER="0"
 SRC="img35.png"
 ALT="$ n$">
 from start, bottom of window
<BR>
M&amp;middle line of window
<BR>&amp;
<BR>
multicolumn2lbf Insertion &amp; replace <IMG
 WIDTH="16" HEIGHT="29" ALIGN="BOTTOM" BORDER="0"
 SRC="img37.png"
 ALT="$ to$">
 insert mode
<BR>
hline
&amp;
<BR>
i a&amp;insert before, after cursor
<BR>
I A&amp;insert at beginning, end of line
<BR>
gI&amp;insert text in first column
<BR>
o O&amp;open a new line below, above the current line
<BR>
r<IMG
 WIDTH="15" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img38.png"
 ALT="$ c$">
&amp;replace character under cursor with <IMG
 WIDTH="15" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img38.png"
 ALT="$ c$">

<BR>
gr<IMG
 WIDTH="15" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img38.png"
 ALT="$ c$">
&amp;like tt r, but without affecting layout
<BR>
R&amp;replace characters starting at the cursor
<BR>
gR&amp;like tt R, but without affecting layout
<BR>
c<IMG
 WIDTH="8" HEIGHT="11" ALIGN="BOTTOM" BORDER="0"
 SRC="img39.png"
 ALT="$ m$">
&amp;change text of movement command <IMG
 WIDTH="8" HEIGHT="11" ALIGN="BOTTOM" BORDER="0"
 SRC="img39.png"
 ALT="$ m$">

<BR>
cc or S&amp;change current line
<BR>
C&amp;change to the end of line
<BR>
s&amp;change one character and insert
<BR> ~<br>&amp; switch case and advance cursor
<BR>
g ~<br><IMG
 WIDTH="8" HEIGHT="11" ALIGN="BOTTOM" BORDER="0"
 SRC="img39.png"
 ALT="$ m$">
 &amp; switch case of movement command <IMG
 WIDTH="8" HEIGHT="11" ALIGN="BOTTOM" BORDER="0"
 SRC="img39.png"
 ALT="$ m$">

<BR>
endtabular*
newpage
begintabular*4in rl
multicolumn2lbf Insertion &amp; replace <IMG
 WIDTH="16" HEIGHT="29" ALIGN="BOTTOM" BORDER="0"
 SRC="img37.png"
 ALT="$ to$">
 insert mode (continued)
<BR>
hline
&amp;
<BR>
gu<IMG
 WIDTH="8" HEIGHT="11" ALIGN="BOTTOM" BORDER="0"
 SRC="img39.png"
 ALT="$ m$">
 gU<IMG
 WIDTH="8" HEIGHT="11" ALIGN="BOTTOM" BORDER="0"
 SRC="img39.png"
 ALT="$ m$">
&amp;lowercase, uppercase text of movement <IMG
 WIDTH="8" HEIGHT="11" ALIGN="BOTTOM" BORDER="0"
 SRC="img39.png"
 ALT="$ m$">

<BR><IMG
 WIDTH="16" HEIGHT="11" ALIGN="MIDDLE" BORDER="0"
 SRC="img40.png"
 ALT="$ &lt;$">
<IMG
 WIDTH="8" HEIGHT="11" ALIGN="BOTTOM" BORDER="0"
 SRC="img39.png"
 ALT="$ m$">
 <IMG
 WIDTH="14" HEIGHT="22" ALIGN="MIDDLE" BORDER="0"
 SRC="img41.png"
 ALT="$ &gt;$">
<IMG
 WIDTH="8" HEIGHT="11" ALIGN="BOTTOM" BORDER="0"
 SRC="img39.png"
 ALT="$ m$">
&amp;shift left, right text of movement <IMG
 WIDTH="8" HEIGHT="11" ALIGN="BOTTOM" BORDER="0"
 SRC="img39.png"
 ALT="$ m$">

<BR><IMG
 WIDTH="172" HEIGHT="29" ALIGN="BOTTOM" BORDER="0"
 SRC="img35.png"
 ALT="$ n$">
<IMG
 WIDTH="16" HEIGHT="11" ALIGN="MIDDLE" BORDER="0"
 SRC="img40.png"
 ALT="$ &lt;$">
kern-3pt<IMG
 WIDTH="16" HEIGHT="11" ALIGN="MIDDLE" BORDER="0"
 SRC="img40.png"
 ALT="$ &lt;$">
 <IMG
 WIDTH="172" HEIGHT="29" ALIGN="BOTTOM" BORDER="0"
 SRC="img35.png"
 ALT="$ n$">
<IMG
 WIDTH="14" HEIGHT="22" ALIGN="MIDDLE" BORDER="0"
 SRC="img41.png"
 ALT="$ &gt;$">
kern-3pt<IMG
 WIDTH="14" HEIGHT="22" ALIGN="MIDDLE" BORDER="0"
 SRC="img41.png"
 ALT="$ &gt;$">
&amp;shift <IMG
 WIDTH="172" HEIGHT="29" ALIGN="BOTTOM" BORDER="0"
 SRC="img35.png"
 ALT="$ n$">
 lines left, right
<BR>&amp;
<BR>
multicolumn2lbf Deletion
<BR>
hline
&amp;
<BR>
x X &amp; delete character under, before cursor
<BR>
d<IMG
 WIDTH="8" HEIGHT="11" ALIGN="BOTTOM" BORDER="0"
 SRC="img39.png"
 ALT="$ m$">
 &amp; delete text of movement command <IMG
 WIDTH="8" HEIGHT="11" ALIGN="BOTTOM" BORDER="0"
 SRC="img39.png"
 ALT="$ m$">

<BR>
dd D &amp; delete current line, to the end of line
<BR>
J gJ &amp; join current line with next, without space
<BR>:<IMG
 WIDTH="14" HEIGHT="22" ALIGN="BOTTOM" BORDER="0"
 SRC="img42.png"
 ALT="$ r$">
d<!-- MATH
 $hookleftarrow$
 -->
&amp; delete range <IMG
 WIDTH="14" HEIGHT="22" ALIGN="BOTTOM" BORDER="0"
 SRC="img42.png"
 ALT="$ r$">
 lines
<BR>:<IMG
 WIDTH="14" HEIGHT="22" ALIGN="BOTTOM" BORDER="0"
 SRC="img42.png"
 ALT="$ r$">
d<IMG
 WIDTH="9" HEIGHT="11" ALIGN="BOTTOM" BORDER="0"
 SRC="img43.png"
 ALT="$ x$">
<!-- MATH
 $hookleftarrow$
 -->
&amp; delete range <IMG
 WIDTH="14" HEIGHT="22" ALIGN="BOTTOM" BORDER="0"
 SRC="img42.png"
 ALT="$ r$">
 lines into register <IMG
 WIDTH="9" HEIGHT="11" ALIGN="BOTTOM" BORDER="0"
 SRC="img43.png"
 ALT="$ x$">

<BR>
<p>
&amp;
<BR>
multicolumn2lbf Insert Mode
<BR>
hline
&amp;
<BR>
rmchar94kern-1ptV<IMG
 WIDTH="15" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img38.png"
 ALT="$ c$">
 rmchar94kern-1ptV<IMG
 WIDTH="172" HEIGHT="29" ALIGN="BOTTOM" BORDER="0"
 SRC="img35.png"
 ALT="$ n$">
&amp;insert char <IMG
 WIDTH="15" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img38.png"
 ALT="$ c$">
 literally, decimal value <IMG
 WIDTH="172" HEIGHT="29" ALIGN="BOTTOM" BORDER="0"
 SRC="img35.png"
 ALT="$ n$">

<BR>
rmchar94kern-1ptV<IMG
 WIDTH="172" HEIGHT="29" ALIGN="BOTTOM" BORDER="0"
 SRC="img35.png"
 ALT="$ n$">
&amp;insert decimal value of character
<BR>
rmchar94kern-1ptA&amp;insert previously inserted text
<BR>
rmchar94kern-1pt@&amp;same as ttrmchar94kern-1ptA and stop 
<BR>&amp;insert <IMG
 WIDTH="16" HEIGHT="29" ALIGN="BOTTOM" BORDER="0"
 SRC="img37.png"
 ALT="$ to$">
 command mode
<BR>
rmchar94kern-1ptR<IMG
 WIDTH="9" HEIGHT="11" ALIGN="BOTTOM" BORDER="0"
 SRC="img43.png"
 ALT="$ x$">
 rmchar94kern-1ptRrmchar94kern-1ptR<IMG
 WIDTH="9" HEIGHT="11" ALIGN="BOTTOM" BORDER="0"
 SRC="img43.png"
 ALT="$ x$">
&amp;insert content of register <IMG
 WIDTH="9" HEIGHT="11" ALIGN="BOTTOM" BORDER="0"
 SRC="img43.png"
 ALT="$ x$">
, literally
<BR>
rmchar94kern-1ptN rmchar94kern-1ptP&amp;text completion before, after cursor
<BR>
rmchar94kern-1ptW&amp;delete word before cursor
<BR>
rmchar94kern-1ptU&amp;delete all inserted character in current line
<BR>
rmchar94kern-1ptD rmchar94kern-1ptT&amp;shift left, right one shift width
<BR>
rmchar94kern-1ptK<IMG
 WIDTH="11" HEIGHT="11" ALIGN="MIDDLE" BORDER="0"
 SRC="img44.png"
 ALT="$ c_1$">
<IMG
 WIDTH="16" HEIGHT="18" ALIGN="MIDDLE" BORDER="0"
 SRC="img45.png"
 ALT="$ c_2$">
 or <IMG
 WIDTH="11" HEIGHT="11" ALIGN="MIDDLE" BORDER="0"
 SRC="img44.png"
 ALT="$ c_1$">
kern-1pt<IMG
 WIDTH="16" HEIGHT="18" ALIGN="MIDDLE" BORDER="0"
 SRC="img45.png"
 ALT="$ c_2$">
&amp;enter digraph <!-- MATH
 $\{c_1,c_2\}$
 -->
<IMG
 WIDTH="16" HEIGHT="18" ALIGN="MIDDLE" BORDER="0"
 SRC="img46.png"
 ALT="$ \{c_1,c_2\}$">

<BR>
rmchar94kern-1ptO<IMG
 WIDTH="15" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img38.png"
 ALT="$ c$">
&amp;execute <IMG
 WIDTH="15" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img38.png"
 ALT="$ c$">
 in temporary command mode
<BR>
rmchar94kern-1ptXrmchar94kern-1ptE rmchar94kern-1ptXrmchar94kern-1ptY&amp;scroll up, down
<BR><IMG
 WIDTH="106" HEIGHT="28" ALIGN="MIDDLE" BORDER="0"
 SRC="img2.png"
 ALT="$ langle$">
rmitesc<IMG
 WIDTH="45" HEIGHT="27" ALIGN="MIDDLE" BORDER="0"
 SRC="img3.png"
 ALT="$ rangle$">
 or rmchar94kern-1pt[ &amp; abandon edition <IMG
 WIDTH="16" HEIGHT="29" ALIGN="BOTTOM" BORDER="0"
 SRC="img37.png"
 ALT="$ to$">
 command mode
<BR>&amp;
<BR>
multicolumn2lbf Copying
<BR>
hline
&amp;
<BR>"<IMG
 WIDTH="9" HEIGHT="11" ALIGN="BOTTOM" BORDER="0"
 SRC="img43.png"
 ALT="$ x$">
&amp;use register <IMG
 WIDTH="9" HEIGHT="11" ALIGN="BOTTOM" BORDER="0"
 SRC="img43.png"
 ALT="$ x$">
 for next delete, yank, put
<BR>:reg<!-- MATH
 $hookleftarrow$
 -->
&amp;show the content of all registers
<BR>:reg <IMG
 WIDTH="9" HEIGHT="11" ALIGN="BOTTOM" BORDER="0"
 SRC="img43.png"
 ALT="$ x$">
<!-- MATH
 $hookleftarrow$
 -->
&amp;show the content of registers <IMG
 WIDTH="9" HEIGHT="11" ALIGN="BOTTOM" BORDER="0"
 SRC="img43.png"
 ALT="$ x$">

<BR>
y<IMG
 WIDTH="8" HEIGHT="11" ALIGN="BOTTOM" BORDER="0"
 SRC="img39.png"
 ALT="$ m$">
&amp;yank the text of movement command <IMG
 WIDTH="8" HEIGHT="11" ALIGN="BOTTOM" BORDER="0"
 SRC="img39.png"
 ALT="$ m$">

<BR>
yy or Y&amp;yank current line into register
<BR>
p P&amp;put register after, before cursor position
<BR>]p [p&amp;like tt p, tt P with indent adjusted
<BR>
gp gP&amp;like tt p, tt P leaving cursor after new text
<BR>
endtabular*
newpage
<p>
begintabular*4in rl
multicolumn2lbf Advanced insertion
<BR>
hline
&amp;
<BR>
g?<IMG
 WIDTH="8" HEIGHT="11" ALIGN="BOTTOM" BORDER="0"
 SRC="img39.png"
 ALT="$ m$">
&amp;perform rot13 encoding on movement <IMG
 WIDTH="8" HEIGHT="11" ALIGN="BOTTOM" BORDER="0"
 SRC="img39.png"
 ALT="$ m$">

<BR><IMG
 WIDTH="172" HEIGHT="29" ALIGN="BOTTOM" BORDER="0"
 SRC="img35.png"
 ALT="$ n$">
rmchar94kern-1ptA <IMG
 WIDTH="172" HEIGHT="29" ALIGN="BOTTOM" BORDER="0"
 SRC="img35.png"
 ALT="$ n$">
rmchar94kern-1ptX&amp;<IMG
 WIDTH="53" HEIGHT="29" ALIGN="MIDDLE" BORDER="0"
 SRC="img47.png"
 ALT="$ +n$">
, <IMG
 WIDTH="23" HEIGHT="24" ALIGN="MIDDLE" BORDER="0"
 SRC="img48.png"
 ALT="$ -n$">
 to number under cursor
<BR>
gq<IMG
 WIDTH="8" HEIGHT="11" ALIGN="BOTTOM" BORDER="0"
 SRC="img39.png"
 ALT="$ m$">
&amp;format lines of movement <IMG
 WIDTH="8" HEIGHT="11" ALIGN="BOTTOM" BORDER="0"
 SRC="img39.png"
 ALT="$ m$">
 to fixed width
<BR>:<IMG
 WIDTH="14" HEIGHT="22" ALIGN="BOTTOM" BORDER="0"
 SRC="img42.png"
 ALT="$ r$">
ce <IMG
 WIDTH="23" HEIGHT="21" ALIGN="BOTTOM" BORDER="0"
 SRC="img49.png"
 ALT="$ w$">
<!-- MATH
 $hookleftarrow$
 -->
&amp;center lines in range <IMG
 WIDTH="14" HEIGHT="22" ALIGN="BOTTOM" BORDER="0"
 SRC="img42.png"
 ALT="$ r$">
 to width <IMG
 WIDTH="23" HEIGHT="21" ALIGN="BOTTOM" BORDER="0"
 SRC="img49.png"
 ALT="$ w$">

<BR>:<IMG
 WIDTH="14" HEIGHT="22" ALIGN="BOTTOM" BORDER="0"
 SRC="img42.png"
 ALT="$ r$">
le <IMG
 WIDTH="13" HEIGHT="11" ALIGN="BOTTOM" BORDER="0"
 SRC="img50.png"
 ALT="$ i$">
<!-- MATH
 $hookleftarrow$
 -->
&amp;left align lines in range <IMG
 WIDTH="14" HEIGHT="22" ALIGN="BOTTOM" BORDER="0"
 SRC="img42.png"
 ALT="$ r$">
 with indent <IMG
 WIDTH="13" HEIGHT="11" ALIGN="BOTTOM" BORDER="0"
 SRC="img50.png"
 ALT="$ i$">

<BR>:<IMG
 WIDTH="14" HEIGHT="22" ALIGN="BOTTOM" BORDER="0"
 SRC="img42.png"
 ALT="$ r$">
ri <IMG
 WIDTH="23" HEIGHT="21" ALIGN="BOTTOM" BORDER="0"
 SRC="img49.png"
 ALT="$ w$">
<!-- MATH
 $hookleftarrow$
 -->
&amp;right align lines in range <IMG
 WIDTH="14" HEIGHT="22" ALIGN="BOTTOM" BORDER="0"
 SRC="img42.png"
 ALT="$ r$">
 to width <IMG
 WIDTH="23" HEIGHT="21" ALIGN="BOTTOM" BORDER="0"
 SRC="img49.png"
 ALT="$ w$">

<BR>!<IMG
 WIDTH="8" HEIGHT="11" ALIGN="BOTTOM" BORDER="0"
 SRC="img39.png"
 ALT="$ m$">
<IMG
 WIDTH="15" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img38.png"
 ALT="$ c$">
<!-- MATH
 $hookleftarrow$
 -->
&amp;filter lines of movement <IMG
 WIDTH="8" HEIGHT="11" ALIGN="BOTTOM" BORDER="0"
 SRC="img39.png"
 ALT="$ m$">
 through command <IMG
 WIDTH="15" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img38.png"
 ALT="$ c$">

<BR><IMG
 WIDTH="172" HEIGHT="29" ALIGN="BOTTOM" BORDER="0"
 SRC="img35.png"
 ALT="$ n$">
!!<IMG
 WIDTH="15" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img38.png"
 ALT="$ c$">
<!-- MATH
 $hookleftarrow$
 -->
&amp;filter <IMG
 WIDTH="172" HEIGHT="29" ALIGN="BOTTOM" BORDER="0"
 SRC="img35.png"
 ALT="$ n$">
 lines through command <IMG
 WIDTH="15" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img38.png"
 ALT="$ c$">

<BR>:<IMG
 WIDTH="14" HEIGHT="22" ALIGN="BOTTOM" BORDER="0"
 SRC="img42.png"
 ALT="$ r$">
!<IMG
 WIDTH="15" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img38.png"
 ALT="$ c$">
<!-- MATH
 $hookleftarrow$
 -->
&amp;filter range <IMG
 WIDTH="14" HEIGHT="22" ALIGN="BOTTOM" BORDER="0"
 SRC="img42.png"
 ALT="$ r$">
 lines through command <IMG
 WIDTH="15" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img38.png"
 ALT="$ c$">

<BR>&amp;
<BR>
multicolumn2lbf Visual mode
<BR>
hline
&amp;
<BR>
v V rmchar94kern-1ptV&amp;start/stop highlighting characters, lines, block
<BR>
o&amp;exchange cursor position with start of
<BR>&amp; highlighting
<BR>
gv&amp;start highlighting on previous visual area
<BR>
aw as ap&amp;select a word, a sentence, a paragraph
<BR>
ab aB&amp;select a block ( ), a block ttchar123  ttchar125 
<BR>
<p>
&amp;
<BR>
multicolumn2lbf Undoing,repeating, &amp; registers
<BR>
hline
&amp;
<BR>
u U&amp;undo last command, restore last changed line
<BR>.thinspacethinspacermchar94kern-1ptR&amp;repeat last changes, redo last undo
<BR><IMG
 WIDTH="172" HEIGHT="29" ALIGN="BOTTOM" BORDER="0"
 SRC="img35.png"
 ALT="$ n$">
. &amp;repeat last changes with count replaced by <IMG
 WIDTH="172" HEIGHT="29" ALIGN="BOTTOM" BORDER="0"
 SRC="img35.png"
 ALT="$ n$">

<BR>
q<IMG
 WIDTH="15" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img38.png"
 ALT="$ c$">
 q<IMG
 WIDTH="7" HEIGHT="15" ALIGN="BOTTOM" BORDER="0"
 SRC="img51.png"
 ALT="$ C$">
&amp;record, append typed characters in register <IMG
 WIDTH="15" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img38.png"
 ALT="$ c$">

<BR>
q&amp;stop recording
<BR>@<IMG
 WIDTH="15" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img38.png"
 ALT="$ c$">
&amp;execute the content of register <IMG
 WIDTH="15" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img38.png"
 ALT="$ c$">

<BR>@@&amp;repeat previous tt @ command
<BR>:@<IMG
 WIDTH="15" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img38.png"
 ALT="$ c$">
<!-- MATH
 $hookleftarrow$
 -->
&amp;execute register <IMG
 WIDTH="15" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img38.png"
 ALT="$ c$">
 as an it Ex command
<BR>:<IMG
 WIDTH="14" HEIGHT="22" ALIGN="BOTTOM" BORDER="0"
 SRC="img42.png"
 ALT="$ r$">
g/<IMG
 WIDTH="14" HEIGHT="16" ALIGN="MIDDLE" BORDER="0"
 SRC="img52.png"
 ALT="$ p$">
/<IMG
 WIDTH="15" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img38.png"
 ALT="$ c$">
<!-- MATH
 $hookleftarrow$
 -->
&amp;execute it Ex command <IMG
 WIDTH="15" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img38.png"
 ALT="$ c$">
 on range <IMG
 WIDTH="14" HEIGHT="22" ALIGN="BOTTOM" BORDER="0"
 SRC="img42.png"
 ALT="$ r$">

<BR>&amp;where pattern <IMG
 WIDTH="14" HEIGHT="16" ALIGN="MIDDLE" BORDER="0"
 SRC="img52.png"
 ALT="$ p$">
 matches
<BR>&amp;
<BR>
multicolumn2lbf Complex Movement
<BR>
hline
&amp;
<BR>- +&amp;line up, down on first non-blank character
<BR>
B W&amp;space-separated word left, right
<BR>
gE E&amp;end of space-separated word left, right
<BR><IMG
 WIDTH="172" HEIGHT="29" ALIGN="BOTTOM" BORDER="0"
 SRC="img35.png"
 ALT="$ n$">
_&amp;down <IMG
 WIDTH="11" HEIGHT="18" ALIGN="MIDDLE" BORDER="0"
 SRC="img53.png"
 ALT="$ n-1$">
 line on first non-blank character
<BR>
g0&amp;beginning of it screen line
<BR>
g^ g$&amp;first, last character of it screen line
<BR>
gk gj&amp;it screen line up, down
<BR>&amp;
<BR>
endtabular*
newpage
begintabular*4in rl
multicolumn2lbf Complex Movement (continued)
<BR>
hline
&amp;
<BR>
f<IMG
 WIDTH="15" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img38.png"
 ALT="$ c$">
 F<IMG
 WIDTH="15" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img38.png"
 ALT="$ c$">
&amp;next, previous occurence of character <IMG
 WIDTH="15" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img38.png"
 ALT="$ c$">

<BR>
t<IMG
 WIDTH="15" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img38.png"
 ALT="$ c$">
 T<IMG
 WIDTH="15" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img38.png"
 ALT="$ c$">
&amp;before next, previous occurence of <IMG
 WIDTH="15" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img38.png"
 ALT="$ c$">

<BR>; ,&amp;repeat last tt fFtT, in opposite direction
<BR> [[ ]]<br>&amp;start of  backward, forward
<BR> [] ][<br>&amp;end of  backward, forward
<BR> [( ])<br> &amp;unclosed (, ) backward, forward
<BR> [<br>char123   ]<br>char125 &amp;unclosed ttchar123 , ttchar125  backward, forward
<BR> [m ]m<br> &amp;start of backward, forward it Java method
<BR> [<br>#  ]<br># &amp;unclosed tt#if, tt#else, tt#endif backward,
<BR>&amp; forward
<BR>
<p>
 [* ]*<br>&amp;start, end of tt/* */ backward, forward
<BR>&amp;
<BR>
multicolumn2lbf Search &amp; substitution
<BR>
hline
&amp;
<BR>/<IMG
 WIDTH="39" HEIGHT="26" ALIGN="BOTTOM" BORDER="0"
 SRC="img54.png"
 ALT="$ s$">
<!-- MATH
 $hookleftarrow$
 -->
 ?<IMG
 WIDTH="39" HEIGHT="26" ALIGN="BOTTOM" BORDER="0"
 SRC="img54.png"
 ALT="$ s$">
<!-- MATH
 $hookleftarrow$
 -->
&amp;search forward, backward for <IMG
 WIDTH="39" HEIGHT="26" ALIGN="BOTTOM" BORDER="0"
 SRC="img54.png"
 ALT="$ s$">

<BR>/<IMG
 WIDTH="39" HEIGHT="26" ALIGN="BOTTOM" BORDER="0"
 SRC="img54.png"
 ALT="$ s$">
/<IMG
 WIDTH="9" HEIGHT="11" ALIGN="BOTTOM" BORDER="0"
 SRC="img55.png"
 ALT="$ o$">
<!-- MATH
 $hookleftarrow$
 -->
 ?<IMG
 WIDTH="39" HEIGHT="26" ALIGN="BOTTOM" BORDER="0"
 SRC="img54.png"
 ALT="$ s$">
?<IMG
 WIDTH="9" HEIGHT="11" ALIGN="BOTTOM" BORDER="0"
 SRC="img55.png"
 ALT="$ o$">
<!-- MATH
 $hookleftarrow$
 -->
&amp;search fwd, bwd for <IMG
 WIDTH="39" HEIGHT="26" ALIGN="BOTTOM" BORDER="0"
 SRC="img54.png"
 ALT="$ s$">
 with offset <IMG
 WIDTH="9" HEIGHT="11" ALIGN="BOTTOM" BORDER="0"
 SRC="img55.png"
 ALT="$ o$">

<BR>
n or /<!-- MATH
 $hookleftarrow$
 -->
&amp;repeat forward last search
<BR>
N or ?<!-- MATH
 $hookleftarrow$
 -->
&amp;repeat backward last search
<BR># *&amp;search backward, forward for word 
<BR>&amp;under cursor
<BR>
g# g*&amp;same, but also find partial matches
<BR>
gd gD&amp;local, global definition of symbol 
<BR>&amp;under cursor
<BR>:<IMG
 WIDTH="14" HEIGHT="22" ALIGN="BOTTOM" BORDER="0"
 SRC="img42.png"
 ALT="$ r$">
s/<IMG
 WIDTH="9" HEIGHT="11" ALIGN="MIDDLE" BORDER="0"
 SRC="img56.png"
 ALT="$ f$">
/<IMG
 WIDTH="11" HEIGHT="28" ALIGN="BOTTOM" BORDER="0"
 SRC="img57.png"
 ALT="$ t$">
/<IMG
 WIDTH="9" HEIGHT="11" ALIGN="BOTTOM" BORDER="0"
 SRC="img43.png"
 ALT="$ x$">
<!-- MATH
 $hookleftarrow$
 -->
&amp;substitute <IMG
 WIDTH="9" HEIGHT="11" ALIGN="MIDDLE" BORDER="0"
 SRC="img56.png"
 ALT="$ f$">
 by <IMG
 WIDTH="11" HEIGHT="28" ALIGN="BOTTOM" BORDER="0"
 SRC="img57.png"
 ALT="$ t$">
 in range <IMG
 WIDTH="14" HEIGHT="22" ALIGN="BOTTOM" BORDER="0"
 SRC="img42.png"
 ALT="$ r$">

<BR>&amp;<IMG
 WIDTH="7" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img58.png"
 ALT="$ x:$">
 tt g--all occurrences, tt c--confirm changes
<BR>:<IMG
 WIDTH="14" HEIGHT="22" ALIGN="BOTTOM" BORDER="0"
 SRC="img42.png"
 ALT="$ r$">
s <IMG
 WIDTH="9" HEIGHT="11" ALIGN="BOTTOM" BORDER="0"
 SRC="img43.png"
 ALT="$ x$">
<!-- MATH
 $hookleftarrow$
 -->
&amp;repeat substitution with new <IMG
 WIDTH="14" HEIGHT="22" ALIGN="BOTTOM" BORDER="0"
 SRC="img42.png"
 ALT="$ r$">
 &amp; <IMG
 WIDTH="9" HEIGHT="11" ALIGN="BOTTOM" BORDER="0"
 SRC="img43.png"
 ALT="$ x$">

<BR>&amp;
<BR>
multicolumn2lbf Special characters in search patterns
<BR>
hline
&amp;
<BR>.thinspacethinspacethinspacermchar94kern-1pt $&amp;any single character, start, end of line
<BR>
char92 <IMG
 WIDTH="16" HEIGHT="11" ALIGN="MIDDLE" BORDER="0"
 SRC="img40.png"
 ALT="$ &lt;$">
 char92 <IMG
 WIDTH="14" HEIGHT="22" ALIGN="MIDDLE" BORDER="0"
 SRC="img41.png"
 ALT="$ &gt;$">
&amp;start, end of word
<BR> [<br><IMG
 WIDTH="20" HEIGHT="11" ALIGN="MIDDLE" BORDER="0"
 SRC="img59.png"
 ALT="$ c_1..c_2$">
 ]<br>&amp;a single character in range <IMG
 WIDTH="20" HEIGHT="11" ALIGN="MIDDLE" BORDER="0"
 SRC="img59.png"
 ALT="$ c_1..c_2$">

<BR> [<br>rmchar94kern-1pt<IMG
 WIDTH="20" HEIGHT="11" ALIGN="MIDDLE" BORDER="0"
 SRC="img59.png"
 ALT="$ c_1..c_2$">
 ]<br>&amp;a single character not in range
<BR>
char92 i char92 k char92 I char92 K&amp;an identifier, keyword; excl. digits
<BR>
char92 f char92 p char92 F char92 P&amp;a file name, printable char.; excl. digits
<BR>
char92 s char92 S&amp;a white space, a non-white space
<BR>
char92 e char92 t char92 r char92 b&amp;<IMG
 WIDTH="106" HEIGHT="28" ALIGN="MIDDLE" BORDER="0"
 SRC="img2.png"
 ALT="$ langle$">
rmit esc<IMG
 WIDTH="45" HEIGHT="27" ALIGN="MIDDLE" BORDER="0"
 SRC="img3.png"
 ALT="$ rangle$">
, <IMG
 WIDTH="106" HEIGHT="28" ALIGN="MIDDLE" BORDER="0"
 SRC="img2.png"
 ALT="$ langle$">
rmit tab<IMG
 WIDTH="45" HEIGHT="27" ALIGN="MIDDLE" BORDER="0"
 SRC="img3.png"
 ALT="$ rangle$">
, <IMG
 WIDTH="106" HEIGHT="28" ALIGN="MIDDLE" BORDER="0"
 SRC="img2.png"
 ALT="$ langle$">
rmit<!-- MATH
 $hookleftarrow$
 -->
<IMG
 WIDTH="45" HEIGHT="27" ALIGN="MIDDLE" BORDER="0"
 SRC="img3.png"
 ALT="$ rangle$">
, <IMG
 WIDTH="106" HEIGHT="28" ALIGN="MIDDLE" BORDER="0"
 SRC="img2.png"
 ALT="$ langle$">
rmit<IMG
 WIDTH="38" HEIGHT="18" ALIGN="MIDDLE" BORDER="0"
 SRC="img60.png"
 ALT="$ gets$">
<IMG
 WIDTH="45" HEIGHT="27" ALIGN="MIDDLE" BORDER="0"
 SRC="img3.png"
 ALT="$ rangle$">

<BR>
char92 = * char92 +&amp;match <IMG
 WIDTH="30" HEIGHT="24" ALIGN="BOTTOM" BORDER="0"
 SRC="img61.png"
 ALT="$ 0..1$">
, <IMG
 WIDTH="26" HEIGHT="14" ALIGN="MIDDLE" BORDER="0"
 SRC="img62.png"
 ALT="$ 0..infty$">
, <IMG
 WIDTH="57" HEIGHT="28" ALIGN="MIDDLE" BORDER="0"
 SRC="img63.png"
 ALT="$ 1..infty$">
 of preceding atoms
<BR>
endtabular*
newpage
begintabular*4in rl
multicolumn2lbf Special characters in search patterns (continued)
<BR>
hline
&amp;
<BR>
char92 <IMG
 WIDTH="57" HEIGHT="28" ALIGN="MIDDLE" BORDER="0"
 SRC="img64.png"
 ALT="$ \vert$">
&amp;separate two branches (<IMG
 WIDTH="6" HEIGHT="29" ALIGN="MIDDLE" BORDER="0"
 SRC="img65.png"
 ALT="$ equiv$">
 it or)
<BR>
char92 ( char92 )&amp;group patterns into an atom
<BR>
char92 &amp; char92 <IMG
 WIDTH="172" HEIGHT="29" ALIGN="BOTTOM" BORDER="0"
 SRC="img35.png"
 ALT="$ n$">
&amp;the whole matched pattern, <IMG
 WIDTH="40" HEIGHT="26" ALIGN="BOTTOM" BORDER="0"
 SRC="img66.png"
 ALT="$ n^{th}$">
 tt() group
<BR>
char92 u char92 l&amp;next character made upper, lowercase
<BR>
<p>
multicolumn2lbf Offsets in search commands
<BR>
hline
&amp;
<BR><IMG
 WIDTH="172" HEIGHT="29" ALIGN="BOTTOM" BORDER="0"
 SRC="img35.png"
 ALT="$ n$">
 or +<IMG
 WIDTH="172" HEIGHT="29" ALIGN="BOTTOM" BORDER="0"
 SRC="img35.png"
 ALT="$ n$">
&amp;<IMG
 WIDTH="172" HEIGHT="29" ALIGN="BOTTOM" BORDER="0"
 SRC="img35.png"
 ALT="$ n$">
 line downward in column 1
<BR>-<IMG
 WIDTH="172" HEIGHT="29" ALIGN="BOTTOM" BORDER="0"
 SRC="img35.png"
 ALT="$ n$">
&amp;<IMG
 WIDTH="172" HEIGHT="29" ALIGN="BOTTOM" BORDER="0"
 SRC="img35.png"
 ALT="$ n$">
 line upward in column 1
<BR>
e+<IMG
 WIDTH="172" HEIGHT="29" ALIGN="BOTTOM" BORDER="0"
 SRC="img35.png"
 ALT="$ n$">
 e-<IMG
 WIDTH="172" HEIGHT="29" ALIGN="BOTTOM" BORDER="0"
 SRC="img35.png"
 ALT="$ n$">
&amp;<IMG
 WIDTH="172" HEIGHT="29" ALIGN="BOTTOM" BORDER="0"
 SRC="img35.png"
 ALT="$ n$">
 characters right, left to end of match
<BR>
s+<IMG
 WIDTH="172" HEIGHT="29" ALIGN="BOTTOM" BORDER="0"
 SRC="img35.png"
 ALT="$ n$">
 s-<IMG
 WIDTH="172" HEIGHT="29" ALIGN="BOTTOM" BORDER="0"
 SRC="img35.png"
 ALT="$ n$">
&amp;<IMG
 WIDTH="172" HEIGHT="29" ALIGN="BOTTOM" BORDER="0"
 SRC="img35.png"
 ALT="$ n$">
 characters right, left to start of match
<BR>;<IMG
 WIDTH="24" HEIGHT="18" ALIGN="BOTTOM" BORDER="0"
 SRC="img67.png"
 ALT="$ sc$">
&amp;execute search command <IMG
 WIDTH="24" HEIGHT="18" ALIGN="BOTTOM" BORDER="0"
 SRC="img67.png"
 ALT="$ sc$">
 next
<BR>&amp;
<BR>
multicolumn2lbf Marks &amp; motions
<BR>
hline
&amp;
<BR>
m<IMG
 WIDTH="15" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img38.png"
 ALT="$ c$">
&amp;mark current position with mark <IMG
 WIDTH="16" HEIGHT="11" ALIGN="MIDDLE" BORDER="0"
 SRC="img68.png"
 ALT="$ cin[a..Z]$">

<BR>`<IMG
 WIDTH="15" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img38.png"
 ALT="$ c$">
 `<IMG
 WIDTH="7" HEIGHT="15" ALIGN="BOTTOM" BORDER="0"
 SRC="img51.png"
 ALT="$ C$">
&amp;go to mark <IMG
 WIDTH="15" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img38.png"
 ALT="$ c$">
 in current, <IMG
 WIDTH="7" HEIGHT="15" ALIGN="BOTTOM" BORDER="0"
 SRC="img51.png"
 ALT="$ C$">
 in any file
<BR>`<IMG
 WIDTH="62" HEIGHT="29" ALIGN="BOTTOM" BORDER="0"
 SRC="img69.png"
 ALT="$ 0..9$">
&amp;go to last exit position
<BR>``  `"&amp;go to position before jump, at last edit
<BR>`[ `]&amp;go to start, end of previously operated text
<BR>:marks<!-- MATH
 $hookleftarrow$
 -->
&amp;print the active marks list
<BR>:jumps<!-- MATH
 $hookleftarrow$
 -->
&amp;print the jump list
<BR><IMG
 WIDTH="172" HEIGHT="29" ALIGN="BOTTOM" BORDER="0"
 SRC="img35.png"
 ALT="$ n$">
rmchar94kern-1ptO&amp;go to <IMG
 WIDTH="40" HEIGHT="26" ALIGN="BOTTOM" BORDER="0"
 SRC="img66.png"
 ALT="$ n^{th}$">
 older position in jump list
<BR><IMG
 WIDTH="172" HEIGHT="29" ALIGN="BOTTOM" BORDER="0"
 SRC="img35.png"
 ALT="$ n$">
rmchar94kern-1ptI&amp;go to <IMG
 WIDTH="40" HEIGHT="26" ALIGN="BOTTOM" BORDER="0"
 SRC="img66.png"
 ALT="$ n^{th}$">
 newer position in jump list
<BR>&amp;
<BR>
multicolumn2lbf Key mapping &amp; abbreviations 
<BR>
hline
&amp;
<BR>
<p>
:map <IMG
 WIDTH="15" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img38.png"
 ALT="$ c$">
 <IMG
 WIDTH="26" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img70.png"
 ALT="$ e$">
<!-- MATH
 $hookleftarrow$
 -->
&amp;map <IMG
 WIDTH="9" HEIGHT="11" ALIGN="MIDDLE" BORDER="0"
 SRC="img71.png"
 ALT="$ cmapsto e$">
 in normal &amp; visual mode
<BR>:map! <IMG
 WIDTH="15" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img38.png"
 ALT="$ c$">
 <IMG
 WIDTH="26" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img70.png"
 ALT="$ e$">
<!-- MATH
 $hookleftarrow$
 -->
&amp;map <IMG
 WIDTH="9" HEIGHT="11" ALIGN="MIDDLE" BORDER="0"
 SRC="img71.png"
 ALT="$ cmapsto e$">
 in insert &amp; cmd-line mode
<BR>:unmap! <IMG
 WIDTH="15" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img38.png"
 ALT="$ c$">
<!-- MATH
 $hookleftarrow$
 -->
&amp;remove mapping <IMG
 WIDTH="15" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img38.png"
 ALT="$ c$">

<BR>:mk <IMG
 WIDTH="9" HEIGHT="11" ALIGN="MIDDLE" BORDER="0"
 SRC="img56.png"
 ALT="$ f$">
<!-- MATH
 $hookleftarrow$
 -->
&amp;write current mappings, settings... to file <IMG
 WIDTH="9" HEIGHT="11" ALIGN="MIDDLE" BORDER="0"
 SRC="img56.png"
 ALT="$ f$">

<BR>:ab <IMG
 WIDTH="15" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img38.png"
 ALT="$ c$">
 <IMG
 WIDTH="26" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img70.png"
 ALT="$ e$">
<!-- MATH
 $hookleftarrow$
 -->
&amp;add abbreviation for <IMG
 WIDTH="9" HEIGHT="11" ALIGN="MIDDLE" BORDER="0"
 SRC="img71.png"
 ALT="$ cmapsto e$">

<BR>:ab <IMG
 WIDTH="15" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img38.png"
 ALT="$ c$">
<!-- MATH
 $hookleftarrow$
 -->
&amp;show abbreviations starting with <IMG
 WIDTH="15" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img38.png"
 ALT="$ c$">

<BR>:una <IMG
 WIDTH="15" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img38.png"
 ALT="$ c$">
<!-- MATH
 $hookleftarrow$
 -->
&amp;remove abbreviation <IMG
 WIDTH="15" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img38.png"
 ALT="$ c$">

<BR>&amp;
<BR>
multicolumn2lbf Tags 
<BR>
hline
&amp;
<BR>:ta <IMG
 WIDTH="11" HEIGHT="28" ALIGN="BOTTOM" BORDER="0"
 SRC="img57.png"
 ALT="$ t$">
<!-- MATH
 $hookleftarrow$
 -->
&amp;jump to tag <IMG
 WIDTH="11" HEIGHT="28" ALIGN="BOTTOM" BORDER="0"
 SRC="img57.png"
 ALT="$ t$">

<BR>:<IMG
 WIDTH="172" HEIGHT="29" ALIGN="BOTTOM" BORDER="0"
 SRC="img35.png"
 ALT="$ n$">
ta<!-- MATH
 $hookleftarrow$
 -->
&amp;jump to <IMG
 WIDTH="40" HEIGHT="26" ALIGN="BOTTOM" BORDER="0"
 SRC="img66.png"
 ALT="$ n^{th}$">
 newer tag in list
<BR>
rmchar94kern-1pt] rmchar94kern-1ptT&amp;jump to the tag under cursor, return 
<BR>&amp;from tag
<BR>:ts <IMG
 WIDTH="11" HEIGHT="28" ALIGN="BOTTOM" BORDER="0"
 SRC="img57.png"
 ALT="$ t$">
<!-- MATH
 $hookleftarrow$
 -->
&amp;list matching tags and select one for jump
<BR>
endtabular*
<p>
begintabular*4in rl
multicolumn2lbf Tags (continued)
<BR>
hline
&amp;
<BR>:tj <IMG
 WIDTH="11" HEIGHT="28" ALIGN="BOTTOM" BORDER="0"
 SRC="img57.png"
 ALT="$ t$">
<!-- MATH
 $hookleftarrow$
 -->
&amp;jump to tag or select one if multiple
<BR>&amp; matches
<BR>:tags<!-- MATH
 $hookleftarrow$
 -->
&amp;print tag list
<BR>:<IMG
 WIDTH="172" HEIGHT="29" ALIGN="BOTTOM" BORDER="0"
 SRC="img35.png"
 ALT="$ n$">
po<!-- MATH
 $hookleftarrow$
 -->
 :<IMG
 WIDTH="172" HEIGHT="29" ALIGN="BOTTOM" BORDER="0"
 SRC="img35.png"
 ALT="$ n$">
rmchar94kern-1ptT<!-- MATH
 $hookleftarrow$
 -->
&amp;jump back from, to <IMG
 WIDTH="40" HEIGHT="26" ALIGN="BOTTOM" BORDER="0"
 SRC="img66.png"
 ALT="$ n^{th}$">
 older tag
<BR>:<IMG
 WIDTH="172" HEIGHT="29" ALIGN="BOTTOM" BORDER="0"
 SRC="img35.png"
 ALT="$ n$">
po<!-- MATH
 $hookleftarrow$
 -->
&amp;jump back from <IMG
 WIDTH="40" HEIGHT="26" ALIGN="BOTTOM" BORDER="0"
 SRC="img66.png"
 ALT="$ n^{th}$">
 older tag in tag list
<BR>:tl<!-- MATH
 $hookleftarrow$
 -->
&amp;jump to last matching tag
<BR>
rmchar94kern-1ptWchar125  :pt <IMG
 WIDTH="11" HEIGHT="28" ALIGN="BOTTOM" BORDER="0"
 SRC="img57.png"
 ALT="$ t$">
<!-- MATH
 $hookleftarrow$
 -->
&amp;preview tag under cursor, tag <IMG
 WIDTH="11" HEIGHT="28" ALIGN="BOTTOM" BORDER="0"
 SRC="img57.png"
 ALT="$ t$">

<BR>
rmchar94kern-1ptW ]<br>&amp;split window and show tag under cursor
<BR>
rmchar94kern-1ptWz or :pc<!-- MATH
 $hookleftarrow$
 -->
&amp;close tag preview window
<BR>&amp;
<BR>
multicolumn2lbf Scrolling &amp; multi-windowing 
<BR>
hline
&amp;
<BR>
rmchar94kern-1ptE rmchar94kern-1ptY&amp;scroll line up, down
<BR>
rmchar94kern-1ptD rmchar94kern-1ptU&amp;scroll half a page up, down
<BR>
rmchar94kern-1ptF rmchar94kern-1ptB&amp;scroll page up, down
<BR>
zt or z<!-- MATH
 $hookleftarrow$
 -->
&amp;set current line at top of window
<BR>
zz or z. &amp;set current line at center of window
<BR>
zb or z-&amp;set current line at bottom of window
<BR>
zh zl&amp;scroll one character to the right, left
<BR>
zH zL&amp;scroll half a screen to the right, left
<BR>
rmchar94kern-1ptWs or :split<!-- MATH
 $hookleftarrow$
 -->
&amp;split window in two
<BR>
rmchar94kern-1ptWn or :new<!-- MATH
 $hookleftarrow$
 -->
&amp;create new empty window
<BR>
rmchar94kern-1ptWo or :on<!-- MATH
 $hookleftarrow$
 -->
&amp;make current window one on screen
<BR>
rmchar94kern-1ptWj or rmchar94kern-1ptWk&amp;move to window below, above
<BR>
rmchar94kern-1ptWw or rmchar94kern-1ptWrmchar94kern-1ptW&amp;move to window below, above (wrap)
<BR>&amp;
<BR>
multicolumn2lbf Ex commands (<!-- MATH
 $hookleftarrow$
 -->
) 
<BR>
hline
&amp;
<BR>:e <IMG
 WIDTH="9" HEIGHT="11" ALIGN="MIDDLE" BORDER="0"
 SRC="img56.png"
 ALT="$ f$">
&amp;edit file <IMG
 WIDTH="9" HEIGHT="11" ALIGN="MIDDLE" BORDER="0"
 SRC="img56.png"
 ALT="$ f$">
, unless changes have 
<BR>&amp;been made
<BR>:e! <IMG
 WIDTH="9" HEIGHT="11" ALIGN="MIDDLE" BORDER="0"
 SRC="img56.png"
 ALT="$ f$">
&amp;edit file <IMG
 WIDTH="9" HEIGHT="11" ALIGN="MIDDLE" BORDER="0"
 SRC="img56.png"
 ALT="$ f$">
 always 
<BR>&amp;(by default reload current)
<BR>:wn :wN&amp;write file and edit next, previous one
<BR>:n :N&amp;edit next, previous file in list
<BR>:<IMG
 WIDTH="14" HEIGHT="22" ALIGN="BOTTOM" BORDER="0"
 SRC="img42.png"
 ALT="$ r$">
w&amp;write range <IMG
 WIDTH="14" HEIGHT="22" ALIGN="BOTTOM" BORDER="0"
 SRC="img42.png"
 ALT="$ r$">
 to current file
<BR>:<IMG
 WIDTH="14" HEIGHT="22" ALIGN="BOTTOM" BORDER="0"
 SRC="img42.png"
 ALT="$ r$">
w <IMG
 WIDTH="9" HEIGHT="11" ALIGN="MIDDLE" BORDER="0"
 SRC="img56.png"
 ALT="$ f$">
&amp;write range <IMG
 WIDTH="14" HEIGHT="22" ALIGN="BOTTOM" BORDER="0"
 SRC="img42.png"
 ALT="$ r$">
 to file <IMG
 WIDTH="9" HEIGHT="11" ALIGN="MIDDLE" BORDER="0"
 SRC="img56.png"
 ALT="$ f$">

<BR>:<IMG
 WIDTH="14" HEIGHT="22" ALIGN="BOTTOM" BORDER="0"
 SRC="img42.png"
 ALT="$ r$">
w<IMG
 WIDTH="14" HEIGHT="22" ALIGN="MIDDLE" BORDER="0"
 SRC="img41.png"
 ALT="$ &gt;$">
kern-3pt<IMG
 WIDTH="14" HEIGHT="22" ALIGN="MIDDLE" BORDER="0"
 SRC="img41.png"
 ALT="$ &gt;$">
<IMG
 WIDTH="9" HEIGHT="11" ALIGN="MIDDLE" BORDER="0"
 SRC="img56.png"
 ALT="$ f$">
&amp;append range <IMG
 WIDTH="14" HEIGHT="22" ALIGN="BOTTOM" BORDER="0"
 SRC="img42.png"
 ALT="$ r$">
 to file <IMG
 WIDTH="9" HEIGHT="11" ALIGN="MIDDLE" BORDER="0"
 SRC="img56.png"
 ALT="$ f$">

<BR>:q :q!&amp;quit and confirm, quit and discard 
<BR>&amp;changes
<BR>:wq or :x or ZZ&amp;write to current file and exit
<BR>
endtabular*
newpage
begintabular*4in rl
multicolumn2lbf Ex commands (continued)
<BR>
hline
&amp;
<BR><IMG
 WIDTH="106" HEIGHT="28" ALIGN="MIDDLE" BORDER="0"
 SRC="img2.png"
 ALT="$ langle$">
rmit up<IMG
 WIDTH="45" HEIGHT="27" ALIGN="MIDDLE" BORDER="0"
 SRC="img3.png"
 ALT="$ rangle$">
 <IMG
 WIDTH="106" HEIGHT="28" ALIGN="MIDDLE" BORDER="0"
 SRC="img2.png"
 ALT="$ langle$">
rmit down<IMG
 WIDTH="45" HEIGHT="27" ALIGN="MIDDLE" BORDER="0"
 SRC="img3.png"
 ALT="$ rangle$">
&amp;recall commands starting with current
<BR>:r <IMG
 WIDTH="9" HEIGHT="11" ALIGN="MIDDLE" BORDER="0"
 SRC="img56.png"
 ALT="$ f$">
&amp;insert content of file <IMG
 WIDTH="9" HEIGHT="11" ALIGN="MIDDLE" BORDER="0"
 SRC="img56.png"
 ALT="$ f$">
 below cursor
<BR>:r! <IMG
 WIDTH="15" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img38.png"
 ALT="$ c$">
&amp;insert output of command <IMG
 WIDTH="15" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img38.png"
 ALT="$ c$">
 below
<BR>&amp; cursor
<BR>:all&amp;open a window for each file in the 
<BR>&amp;argument list
<BR>:args&amp;display the argument list
<BR>&amp;
<BR>
multicolumn2lbf Ex ranges 
<BR>
hline
&amp;
<BR>, ; &amp;separates two lines numbers, set to first line
<BR><IMG
 WIDTH="172" HEIGHT="29" ALIGN="BOTTOM" BORDER="0"
 SRC="img35.png"
 ALT="$ n$">
&amp;an absolute line number <IMG
 WIDTH="172" HEIGHT="29" ALIGN="BOTTOM" BORDER="0"
 SRC="img35.png"
 ALT="$ n$">

<BR>.thinspacethinspacethinspace$&amp;
	the current line, the last line in file
<BR>% *&amp;entire file, visual area
<BR>'<IMG
 WIDTH="11" HEIGHT="28" ALIGN="BOTTOM" BORDER="0"
 SRC="img57.png"
 ALT="$ t$">
&amp;position of mark <IMG
 WIDTH="11" HEIGHT="28" ALIGN="BOTTOM" BORDER="0"
 SRC="img57.png"
 ALT="$ t$">

<BR>/<IMG
 WIDTH="14" HEIGHT="16" ALIGN="MIDDLE" BORDER="0"
 SRC="img52.png"
 ALT="$ p$">
/ ?<IMG
 WIDTH="14" HEIGHT="16" ALIGN="MIDDLE" BORDER="0"
 SRC="img52.png"
 ALT="$ p$">
?&amp;the next, previous line where <IMG
 WIDTH="14" HEIGHT="16" ALIGN="MIDDLE" BORDER="0"
 SRC="img52.png"
 ALT="$ p$">
 matches
<BR>+<IMG
 WIDTH="172" HEIGHT="29" ALIGN="BOTTOM" BORDER="0"
 SRC="img35.png"
 ALT="$ n$">
 -<IMG
 WIDTH="172" HEIGHT="29" ALIGN="BOTTOM" BORDER="0"
 SRC="img35.png"
 ALT="$ n$">
&amp;<IMG
 WIDTH="53" HEIGHT="29" ALIGN="MIDDLE" BORDER="0"
 SRC="img47.png"
 ALT="$ +n$">
, <IMG
 WIDTH="23" HEIGHT="24" ALIGN="MIDDLE" BORDER="0"
 SRC="img48.png"
 ALT="$ -n$">
 to the preceding line number
<BR>
<p>
&amp;
<BR>
multicolumn2lbf Folding 
<BR>
hline
&amp;
<BR>
zf<IMG
 WIDTH="8" HEIGHT="11" ALIGN="BOTTOM" BORDER="0"
 SRC="img39.png"
 ALT="$ m$">
&amp;create fold of movement <IMG
 WIDTH="8" HEIGHT="11" ALIGN="BOTTOM" BORDER="0"
 SRC="img39.png"
 ALT="$ m$">

<BR>:<IMG
 WIDTH="14" HEIGHT="22" ALIGN="BOTTOM" BORDER="0"
 SRC="img42.png"
 ALT="$ r$">
fo&amp;create fold for range <IMG
 WIDTH="14" HEIGHT="22" ALIGN="BOTTOM" BORDER="0"
 SRC="img42.png"
 ALT="$ r$">

<BR>
zd zE&amp;delete fold at cursor, all in window
<BR>
zo zc zO zC&amp;open, close one fold; recursively
<BR> [z ]z<br>&amp;move to start, end of current open fold
<BR>
zj zk&amp;move down, up to start, end of next fold
<BR>&amp;
<BR>
multicolumn2lbf Miscellaneous 
<BR>
hline
&amp;
<BR>:sh<!-- MATH
 $hookleftarrow$
 -->
 :!<IMG
 WIDTH="15" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img38.png"
 ALT="$ c$">
<!-- MATH
 $hookleftarrow$
 -->
&amp;start shell, execute command <IMG
 WIDTH="15" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img38.png"
 ALT="$ c$">
 in shell
<BR>
K&amp;lookup keyword under cursor with tt man
<BR>:make<!-- MATH
 $hookleftarrow$
 -->
&amp;start tt make, read errors and jump to first
<BR>:cn<!-- MATH
 $hookleftarrow$
 -->
 :cp<!-- MATH
 $hookleftarrow$
 -->
&amp;display the next, previous error
<BR>:cl<!-- MATH
 $hookleftarrow$
 -->
 :cf<!-- MATH
 $hookleftarrow$
 -->
&amp;list all errors, read errors from file
<BR>
rmchar94kern-1ptL rmchar94kern-1ptG&amp;redraw screen, show filename and position
<BR>
grmchar94kern-1ptG&amp;show cursor column, line, and 
<BR>&amp;character position
<BR>
ga&amp;show ASCII value of character under cursor
<BR>
gf&amp;open file which filename is under cursor
<BR>:redir<IMG
 WIDTH="14" HEIGHT="22" ALIGN="MIDDLE" BORDER="0"
 SRC="img41.png"
 ALT="$ &gt;$">
<IMG
 WIDTH="9" HEIGHT="11" ALIGN="MIDDLE" BORDER="0"
 SRC="img56.png"
 ALT="$ f$">
<!-- MATH
 $hookleftarrow$
 -->
&amp;redirect output to file <IMG
 WIDTH="9" HEIGHT="11" ALIGN="MIDDLE" BORDER="0"
 SRC="img56.png"
 ALT="$ f$">

<BR>:mkview <IMG
 WIDTH="67" HEIGHT="24" ALIGN="MIDDLE" BORDER="0"
 SRC="img72.png"
 ALT="$ [f]$">
&amp;save view configuration [to file <IMG
 WIDTH="9" HEIGHT="11" ALIGN="MIDDLE" BORDER="0"
 SRC="img56.png"
 ALT="$ f$">
]
<BR>
endtabular*
<p>


 
<p>BASH REFERENCE
indexbash reference
label<p>:bashref
begintabular*4in rl
multicolumn2lbf File Attribute Operators
<BR>
hline
-d it file&amp;it file exists and is a directory
<BR>-e it file&amp;it file exists
<BR>-f it file&amp;it file exists and is a regular it file 
<BR>-r it file&amp;You have read permissions on the it file 
<BR>-s it file&amp;it file exists and is not empty 
<BR>-w it file&amp;You have write permissions on the it file
<BR>-x it file&amp;You have execute permissions on the it file
<BR>-O it file&amp;You own the it file
<BR>-G it file&amp;Files group id matches one of yours
<BR>
it file1 -nt it file2&amp;it file1 is newer than it file2
<BR>
it file1 -ot it file2&amp;it file1 is older than it file2
<BR>
endtabular*
begintabular*4in rl
multicolumn2lbf Arithmetic Test Operators
<BR>
hline
-lt&amp;Less than
<BR>-le&amp;Less than or equal
<BR>-eq&amp;Equal
<BR>-ge&amp;Greater than or equal
<BR>-gt&amp;Greater than
<BR>-ne&amp;Not equal
<BR>
endtabular*
<p>
begintabular*4in rl
multicolumn2lbf Relational Operators 
<BR>
hline
 &lt;<br>&amp;Less than
<BR> &gt;<br>&amp;Greater than
<BR> &lt;<br>=&amp;Less than or equal to
<BR> &gt;<br>=&amp;Greater than or equal to
<BR>== &amp;Equal to
<BR>!= &amp;Not equal to
<BR>
endtabular*
begintabular*4in rl
multicolumn2lbf String Comparison Operators 
<BR>
hline
it str1 = it str2&amp;it str1 equals it str2
<BR>
it str1 != it str2&amp;it str1 does not equal it str2
<BR>
it str1  &lt;<br> it str2&amp;it str1 is less than it str2
<BR>
it str1  &gt;<br> it str2&amp;it str1 is greater than it str2
<BR>-n it str1 &amp;it str1 is not null
<BR>-z it str1 &amp;it str1 is null
<BR>
endtabular*
begintabular*4in rl
multicolumn2lbf Arithmetic Operators 
<BR>
hline
+&amp;Plus
<BR>-&amp;Minus
<BR> *<br>&amp;Multiplication
<BR>/&amp;Division
<BR> %<br>&amp;Remainder
<BR> &lt;&lt;<br>&amp;Bit-shift left
<BR> &gt;&gt;<br>&amp;Bit-shift right
<BR> &amp;<br>&amp;Bitwise and
<BR> |<br>&amp;Bitwise or
<BR> ~<br>&amp;Bitwise not
<BR> !<br>&amp;Bitwise not
<BR> ^<br>&amp;Bitwise exclusive or 
<BR>
endtabular*
begintabular*4in rl
multicolumn2lbf Pattern-Matching Operators
<BR>
hline
 ${variable#pattern}<br>&amp;If the pattern matches the
<BR>
multicolumn2lbeginning of the variables value, delete the shortest part
<BR>
multicolumn2lthat matches and return the rest.
<BR> ${variable##pattern}<br>&amp;If the pattern matches the 
<BR>
multicolumn2lbeginning of the variables value, delete the longest part
<BR>
multicolumn2lthat matches and return the rest.
<BR> ${variable%pattern}<br>&amp;If the pattern matches the 
<BR>
multicolumn2lend of the variables value, delete the shortest part
<BR>
multicolumn2lthat matches and return the rest.
<BR> ${variable%%pattern}<br>&amp;If the pattern matches the 
<BR>
multicolumn2lend of the variables value, delete the longest part
<BR>
multicolumn2lthat matches and return the rest.
<BR> ${variable/pattern/string}<br>&amp;
<BR> ${variable//pattern/string}<br>&amp;The longest match 
<BR>
multicolumn2lto pattern in variable is replaced by string. 
<BR>
multicolumn2lIn the first form only the first match replaced.
<BR>
multicolumn2lIn the second form all matches are replaced. If 
<BR>
multicolumn2lThe pattern begins with # the match must 
<BR>
multicolumn2lbe at the begining. % means the match 
<BR>
multicolumn2lmust be at the end.  If the string is null
<BR>
multicolumn2lthen the matches are deleted.
<BR>
endtabular*
<p>


<p>
 <footer class="foot">

                                <h5>HPC Training - University of South Florida</h5>
                        </footer>

</BODY>
</HTML>
