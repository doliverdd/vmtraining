<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 3.2 Final//EN">

<HTML>
<HEAD>
<TITLE>bcmain</TITLE>
<link rel="stylesheet" href="http://www.w3schools.com/lib/w3.css">
<link rel="stylesheet" type="text/css" href="http://fonts.googleapis.com/css?family=Tangerine">
<LINK REL="STYLESHEET" HREF="../css/main.css">

</HEAD>

<body class="w3-container w3-margin-32" style="width:80%">

<h1>Introduction to High Performance Computing</h1>

<h3>What is High Performance Computing?</h3>

This  will give some background on High Performance Computing and 
define several of the terms that we will use throughout this course.  High 
Performance computing is an often poorly defined concept.
There are several terms that are often confused with High Performance Computing,
such as; High Throughput Computing, Parallel Computing, Numerically 
Intensive Computing, Grid Computing, etc. In fact all of these are facets of 
High Performance Computing.  For our purposes we will define High Performance
Computing to consist of hardware and software resources used for computational
science that are beyond what is commonly found on the desktop machine. 

<h3>HPC Hardware at USF</h3>

There are too many types of advanced hardware to possibly list them all in this book.  In this  we will discuss the types of hardware that are available for HPC from the Research Computing Core at USF. In particular, we will be looking
at the aspects of the different systems that will allow you to make a good 
choice as to which environment is best for the type of problem you are solving. 

<h4>Beowulf Cluster</h4>

Traditionally High Performance computing was only done on large proprietary 
systems. These systems (also known as Big Iron, or super computers)indexBig Iron were expensive,
highly specialized computers that were capable of very fast computations.  They
had several problems.  The programming languages and libraries were not usually
portable, which meant that it was quite expensive to switch between vendors. 
Each machine required personnel trained specifically for that machine,
which added to the expense of switching computer companies.  Also when the speed of these machines was no longer fast, they had to be replaced again at great
expense.  
<p>
Beowulf Cluster Computing uses commodity off the shelf hardware (COTS)
indexCOTS to achieve speeds near those of the Big Iron machines at a much
lower cost.  To achieve this, standard desktop quality computers are connected
together over a network.  These computers then work in parallel to speed 
computation. These cluster computers generally use special 
libraries to handle communications.  
<br>
The systems that you will be working on will use the MPICH libraries. 
Not all computations work well on a cluster computer.  To understand which 
problems lend themselves to the cluster environment we need to take a look at
a property of computer programs called granularity.indexgranularity  
Simply stated, granularity is the ratio between the amount of 
communications and the amount of computation
necessary to solve a problem. When this ratio is low, or when there is not
too much communication, the problem is coarse grained.  If there is a lot of
communication relative to the amount of computation the program is called fine
grained.  The cluster environment is best for medium and coarse grained 
applications. Granularity thus helps us define how effectively 
a program can be subdivided for parallel execution. Coarse grained programs are often referred to as "embarrassingly 
parallel". 
<p>
The Research Computing Core at USF has a 48 node Beowulf Cluster available for
students and faculty.  
<h4>Grid Computing</h4>

Often when doing research the problem is not that the size of the problem is
large, but that the program must be run many times with different initial 
conditions. While a cluster environment may be used, there may be a better 
choice. Since the different instances of the program do not need to communicate,
this is a good choice for using Grid Computing.  Grid Computing is similar
to cluster computing, but the nodes are less tightly coupled.  This means
that communication must be at a minimum.   
<p>
One of the main advantages of using grid computing is that the applications 
do not need to be modified for a parallel environment such as a cluster or 
large scale SMP machine (see below).  
<p>
We provide a grid environment using the Condor system from the University of 
Wisconsin.  The current grid consists of 78 systems. We are also in the
beginning phases of adding a Sun Grid Engine Cluster.  Grid Engine is a 
queuing system that will allow us to make better use of our two and eight way
SMP machines. 

<h4>Large Scale SMP</h4>

Symmetric multi-processor<br>
One type of hardware that can be used for parallel computations is a symmetric
multi-processor or SMP machine.  This machine is characterized by having 
multiple processors that can access a common memory block.  If you have a 
dual processor machine in the office or at home this is more than likely a small
scale SMP machine.  But 
SMP machines can have many more than two processors.  One of the advantages of 
larger scale SMP's is that they are often 64 bit
machines which means that they can address more memory than the average PC. 
This makes these machines the right place for fine grained programs or for
those that require a large memory footprint.
<p>
These machines are often programmed using it threads as a parallel 
programming model.  
<p>
We are currently adding an 8-way SMP machine with 32GB of main memory.

<h3>HPC Software at USF</h3>
There are several areas of software that are of interest when discussing HPC; 
operating systems, libraries, compilers, and applications. We will take up each
of these separately in this .  It should be noted that although much of
the speed of HPC comes from the hardware, it is the software that makes this 
power available to the user.

<h4>Operating Systems</h4>
Most of the systems that are used for HPC at USF run a variation of a Unix
operating system. 

<h4>Linux</h4>

The Linux operating system is the standard for cluster 
computing.  There are several reasons for this.  This variant of Unix is free
and open source.  The cost of proprietary operating systems can greatly increase
the cost of a cluster, which makes Linux more attractive.  Perhaps more 
importantly, the code for the OS is available. This means that researchers can
modify the system. At the current time there is relatively inexpensive 64 bit 
software available for use in clusters.  Linux has one of the best kernels for
this hardware. Some of our systems also run the Solaris operating system.  This
is the Unix variant used on the Sun Micro Systems machines.  These two systems
are very similar in terms of the user interface.  We will be spending some time
learning this interface in the next few days.

<h4>Compilers</h4>

All compilers are not created equal.  Often the execution speed of a program
can be reduced by using the proper compiler and the proper compiler options.  
While the choice of the optimum compiler is not straight forward, some are 
better than others.  We will be concentrating on three compilers.  On machines 
with the Linux operating system we will consider the "Portland Group" compilers
(PG), and the GCC family of compilers. For most HPC applications the PG 
compilers produce more efficient code than the GCC compilers.  The GCC 
compilers are ubiquitous and are included for that reason. On the machines
running the Solaris operating system we have the Sun Suite set of compilers.

<h4>Libraries</h4>

In HPC as in other types of computing you should avoid reinventing the wheel. 
One of the most common ways of doing this is the use of specialized
libraries.  Libraries are precompiled code segments that can be called from
within your program.  Many of the scientific libraries that 
have been optimized over years of development.  This
means that not only is the code already written, but it is usually better than
what an individual programmer could write on their own. 
<h4>Applications</h4>
Often the code needed to solve a research problem has all ready been written.
In some cases this code is offered for free over the Internet.  To use this code
you have to be able to use some of the standard Unix/Linux commands, most 
commonly the "tar" command.  You will have a chance to download and install 
this type of application.  
<p>
Sometimes the code that you need is available on a commercial basis.  Research 
Computing Core Facility has acquired several large scale codes for 
solving a variety of 
scientific problems.  Several of these packages will be discussed and you will 
be given an opportunity to use them.

<p>
<ul class="w3-pagination">
<li><a href="overview.html">Previous</a></li>
  <li><a href="intro.html">Next</a></li>
  
  
</ul>
 <footer class="foot">

                                <h5>HPC Training - University of South Florida</h5>
                        </footer>

</BODY>
</HTML>
